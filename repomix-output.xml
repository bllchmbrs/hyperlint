This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
docs/
  folder_processing.md
examples/
  folder_processing/
    subfolder/
      doc3.md
    doc1.md
    doc2.md
    README.md
src/
  editai/
    editors/
      __init__.py
      ai.py
      arbitrary_links.py
      core.py
      custom_rules.py
      folder_processor.py
      images.py
      links.py
      utils.py
      vale.py
    __init__.py
    cli.py
    py.typed
    utils.py
test_rules/
  bullet_consistency.md
  new_test_rule.md
  passive_voice.md
tests/
  unit/
    editors/
      test_ai_editor.py
      test_base_editor.py
      test_custom_rules_editor.py
    test_cli.py
  conftest.py
  README.md
  test_folder_processor.py
.gitignore
.python-version
main.py
pyproject.toml
README.md
test_sample.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="tests/unit/editors/test_ai_editor.py">
import pytest
from pathlib import Path
from unittest import mock

from editai.editors.ai import AIEditor, LineEdit, LineEdits, CorrectedText


@pytest.fixture
def mock_line_edits():
    """Returns mock line edits for testing."""
    return LineEdits(
        line_edits=[
            LineEdit(
                starting_affected_line=1,
                ending_affected_line=1,
                issue_message="Title should be more descriptive",
                resolution="edit"
            ),
            LineEdit(
                starting_affected_line=3,
                ending_affected_line=3,
                issue_message="Redundant text",
                resolution="delete"
            ),
            LineEdit(
                starting_affected_line=5,
                ending_affected_line=6,
                issue_message="Complex formatting issue",
                resolution="flag"
            )
        ]
    )


class TestAIEditor:
    """Tests for the AIEditor class."""
    
    def test_prerun_checks(self, temp_markdown_file):
        """Test that prerun_checks always returns True."""
        editor = AIEditor(path=temp_markdown_file)
        
        result = editor.prerun_checks()
        
        assert result is True
    
    @mock.patch('editai.editors.ai.get_line_edits')
    def test_fetch_line_edits(self, mock_get_line_edits, temp_markdown_file, mock_line_edits):
        """Test that _fetch_line_edits calls get_line_edits with correct parameters."""
        mock_get_line_edits.return_value = mock_line_edits
        
        editor = AIEditor(path=temp_markdown_file)
        result = editor._fetch_line_edits()
        
        # Verify get_line_edits was called with text_with_line_numbers
        mock_get_line_edits.assert_called_once()
        
        # Verify the result is the mock_line_edits
        assert result == mock_line_edits
    
    @mock.patch('editai.editors.ai.get_line_edits')
    @mock.patch('editai.editors.ai.fix_line_edit')
    def test_collect_issues_with_edit(self, mock_fix_line_edit, mock_get_line_edits, 
                                      temp_markdown_file, mock_line_edits):
        """Test collect_issues with an edit resolution."""
        # Setup mock responses
        mock_get_line_edits.return_value = LineEdits(
            line_edits=[
                LineEdit(
                    starting_affected_line=1,
                    ending_affected_line=1,
                    issue_message="Title should be more descriptive",
                    resolution="edit"
                )
            ]
        )
        mock_fix_line_edit.return_value = "# Enhanced Test Document"
        
        editor = AIEditor(path=temp_markdown_file)
        editor.collect_issues()
        
        # Check that fix_line_edit was called
        mock_fix_line_edit.assert_called_once()
        
        # Verify that both insertion and deletion were created
        assert len(editor.insertions) == 1
        assert len(editor.deletions) == 1
        
        # Check insertion details
        assert editor.insertions[0].line == 1
        assert editor.insertions[0].insert_content == "# Enhanced Test Document"
        
        # Check deletion details
        assert editor.deletions[0].line == 1
        assert editor.deletions[0].existing_content == "# Test Document"
        assert "AI Edit" in editor.deletions[0].issue_message[0]
    
    @mock.patch('editai.editors.ai.get_line_edits')
    def test_collect_issues_with_delete(self, mock_get_line_edits, temp_markdown_file):
        """Test collect_issues with a delete resolution."""
        # Setup mock response
        mock_get_line_edits.return_value = LineEdits(
            line_edits=[
                LineEdit(
                    starting_affected_line=3,
                    ending_affected_line=3,
                    issue_message="Redundant text",
                    resolution="delete"
                )
            ]
        )
        
        editor = AIEditor(path=temp_markdown_file)
        editor.collect_issues()
        
        # Verify that only deletion was created
        assert len(editor.insertions) == 0
        assert len(editor.deletions) == 1
        
        # Check deletion details
        assert editor.deletions[0].line == 3
        assert editor.deletions[0].existing_content == "This is a test."
        assert "Redundant text" in editor.deletions[0].issue_message[0]
    
    @mock.patch('editai.editors.ai.get_line_edits')
    def test_collect_issues_with_flag(self, mock_get_line_edits, complex_markdown_file):
        """Test collect_issues with a flag resolution."""
        # Setup mock response
        mock_get_line_edits.return_value = LineEdits(
            line_edits=[
                LineEdit(
                    starting_affected_line=10,
                    ending_affected_line=12,
                    issue_message="Complex code block issue",
                    resolution="flag"
                )
            ]
        )
        
        editor = AIEditor(path=complex_markdown_file)
        editor.collect_issues()
        
        # Verify that no changes were made
        assert len(editor.insertions) == 0
        assert len(editor.deletions) == 0
    
    @mock.patch('editai.editors.ai.get_line_edits')
    @mock.patch('editai.editors.ai.fix_line_edit')
    def test_collect_issues_with_failed_edit(self, mock_fix_line_edit, mock_get_line_edits, 
                                             temp_markdown_file):
        """Test collect_issues when fix_line_edit returns None."""
        # Setup mock responses
        mock_get_line_edits.return_value = LineEdits(
            line_edits=[
                LineEdit(
                    starting_affected_line=1,
                    ending_affected_line=1,
                    issue_message="Title should be more descriptive",
                    resolution="edit"
                )
            ]
        )
        mock_fix_line_edit.return_value = None  # Simulate API failure
        
        editor = AIEditor(path=temp_markdown_file)
        editor.collect_issues()
        
        # Verify that no changes were made (should treat as flag)
        assert len(editor.insertions) == 0
        assert len(editor.deletions) == 0
    
    @mock.patch('editai.editors.ai.get_line_edits')
    @mock.patch('editai.editors.ai.fix_line_edit')
    def test_collect_issues_with_empty_edit(self, mock_fix_line_edit, mock_get_line_edits, 
                                            temp_markdown_file):
        """Test collect_issues when fix_line_edit returns empty string."""
        # Setup mock responses
        mock_get_line_edits.return_value = LineEdits(
            line_edits=[
                LineEdit(
                    starting_affected_line=1,
                    ending_affected_line=1,
                    issue_message="Title should be removed",
                    resolution="edit"
                )
            ]
        )
        mock_fix_line_edit.return_value = "   "  # Empty string with whitespace
        
        editor = AIEditor(path=temp_markdown_file)
        editor.collect_issues()
        
        # Verify that it was treated as delete
        assert len(editor.insertions) == 0
        assert len(editor.deletions) == 1
    
    @mock.patch('editai.editors.ai.get_line_edits')
    def test_collect_issues_with_invalid_line_numbers(self, mock_get_line_edits, temp_markdown_file):
        """Test collect_issues with invalid line numbers."""
        # Setup mock response with invalid line numbers
        mock_get_line_edits.return_value = LineEdits(
            line_edits=[
                LineEdit(
                    starting_affected_line=100,  # Invalid line number
                    ending_affected_line=101,
                    issue_message="This line doesn't exist",
                    resolution="edit"
                )
            ]
        )
        
        editor = AIEditor(path=temp_markdown_file)
        editor.collect_issues()
        
        # Verify that no changes were made
        assert len(editor.insertions) == 0
        assert len(editor.deletions) == 0
    
    @mock.patch('editai.editors.ai.get_line_edits')
    @mock.patch('editai.editors.ai.fix_line_edit')
    def test_collect_issues_with_overlapping_edits(self, mock_fix_line_edit, mock_get_line_edits, 
                                                  complex_markdown_file):
        """Test collect_issues with overlapping edits."""
        # Setup mock responses with overlapping line edits
        mock_get_line_edits.return_value = LineEdits(
            line_edits=[
                LineEdit(
                    starting_affected_line=1,
                    ending_affected_line=3,
                    issue_message="First edit",
                    resolution="edit"
                ),
                LineEdit(
                    starting_affected_line=2,  # Overlaps with first edit
                    ending_affected_line=4,
                    issue_message="Second edit",
                    resolution="edit"
                )
            ]
        )
        mock_fix_line_edit.return_value = "Modified content"
        
        editor = AIEditor(path=complex_markdown_file)
        editor.collect_issues()
        
        # Verify that only the first edit was applied
        assert len(editor.insertions) > 0
        assert len(editor.deletions) > 0
        
        # Check that only a single set of changes were made
        # This counts the number of unique lines affected by deletions
        affected_lines = set(issue.line for issue in editor.deletions)
        assert len(affected_lines) == 3  # Only lines 1-3 should be affected
    
    @mock.patch('editai.editors.ai.get_line_edits')
    @mock.patch('editai.editors.ai.fix_line_edit')
    def test_generate_v2(self, mock_fix_line_edit, mock_get_line_edits, temp_markdown_file):
        """Test generate_v2 integrates collect_issues and applies changes."""
        # Setup mock responses
        mock_get_line_edits.return_value = LineEdits(
            line_edits=[
                LineEdit(
                    starting_affected_line=1,
                    ending_affected_line=1,
                    issue_message="Title should be more descriptive",
                    resolution="edit"
                )
            ]
        )
        mock_fix_line_edit.return_value = "# Enhanced Test Document"
        
        editor = AIEditor(path=temp_markdown_file)
        result = editor.generate_v2()
        
        # Check the result content
        assert "# Enhanced Test Document" in result
        assert "# Test Document" not in result
        assert "This is a test." in result
    
    @mock.patch('editai.editors.ai.get_line_edits')
    def test_generate_v2_with_no_issues(self, mock_get_line_edits, temp_markdown_file):
        """Test generate_v2 when no issues are found."""
        # Setup mock response with no issues
        mock_get_line_edits.return_value = LineEdits(line_edits=[])
        
        editor = AIEditor(path=temp_markdown_file)
        result = editor.generate_v2()
        
        # Result should be unchanged
        assert result == "# Test Document\n\nThis is a test."
</file>

<file path="tests/unit/editors/test_base_editor.py">
import pytest
from pathlib import Path

from editai.editors.core import (
    BaseEditor, 
    ReplaceLineFixableIssue, 
    InsertLineIssue, 
    DeleteLineIssue,
    DELETE_LINE_MESSAGE
)

class MockEditor(BaseEditor):
    """Mock implementation of BaseEditor for testing."""
    
    def prerun_checks(self) -> bool:
        return True
    
    def collect_issues(self) -> None:
        pass


class TestBaseEditor:
    """Tests for the BaseEditor class."""
    
    def test_get_text(self, temp_markdown_file):
        """Test that get_text properly loads file content."""
        editor = MockEditor(path=temp_markdown_file)
        
        text = editor.get_text()
        
        assert text == "# Test Document\n\nThis is a test."
        assert editor.text == text  # Should be cached
    
    def test_get_line_number_lookup(self, temp_markdown_file):
        """Test that get_line_number_lookup creates correct line mapping."""
        editor = MockEditor(path=temp_markdown_file)
        
        lookup = editor.get_line_number_lookup()
        
        assert lookup == {
            1: "# Test Document",
            2: "",
            3: "This is a test."
        }
    
    def test_get_text_with_line_numbers(self, temp_markdown_file):
        """Test that get_text_with_line_numbers correctly formats text with line numbers."""
        editor = MockEditor(path=temp_markdown_file)
        
        text_with_lines = editor.get_text_with_line_numbers()
        
        assert "1: # Test Document" in text_with_lines
        assert "2: " in text_with_lines
        assert "3: This is a test." in text_with_lines
    
    def test_add_replacement(self, temp_markdown_file):
        """Test that add_replacement correctly adds a replacement issue."""
        editor = MockEditor(path=temp_markdown_file)
        
        issue = ReplaceLineFixableIssue(
            line=1,
            issue_message=["Title should be more descriptive"],
            existing_content="# Test Document"
        )
        
        editor.add_replacement(issue)
        
        assert len(editor.replacements) == 1
        assert editor.replacements[0] == issue
    
    def test_add_insertion(self, temp_markdown_file):
        """Test that add_insertion correctly adds an insertion issue."""
        editor = MockEditor(path=temp_markdown_file)
        
        issue = InsertLineIssue(
            line=2,
            insert_content="This is an inserted line."
        )
        
        editor.add_insertion(issue)
        
        assert len(editor.insertions) == 1
        assert editor.insertions[0] == issue
    
    def test_add_deletion(self, temp_markdown_file):
        """Test that add_deletion correctly adds a deletion issue."""
        editor = MockEditor(path=temp_markdown_file)
        
        issue = DeleteLineIssue(
            line=3,
            issue_message=["This line should be removed"],
            existing_content="This is a test."
        )
        
        editor.add_deletion(issue)
        
        assert len(editor.deletions) == 1
        assert editor.deletions[0] == issue
    
    def test_generate_v2_with_no_changes(self, temp_markdown_file):
        """Test that generate_v2 returns the original text when no issues are collected."""
        editor = MockEditor(path=temp_markdown_file)
        
        result = editor.generate_v2()
        
        assert result == "# Test Document\n\nThis is a test."
    
    def test_generate_v2_with_replacements(self, temp_markdown_file, monkeypatch):
        """Test that generate_v2 correctly applies replacements."""
        # Create a subclass that overrides collect_issues
        class TestEditor(MockEditor):
            def collect_issues(self) -> None:
                # Do nothing, we'll add issues manually
                pass

        editor = TestEditor(path=temp_markdown_file)

        # Mock the fix method to return a known value
        def mock_fix(self):
            return "# Enhanced Test Document"

        monkeypatch.setattr(ReplaceLineFixableIssue, "fix", mock_fix)

        # Add a replacement issue
        issue = ReplaceLineFixableIssue(
            line=1,
            issue_message=["Title should be more descriptive"],
            existing_content="# Test Document"
        )
        editor.add_replacement(issue)

        result = editor.generate_v2()

        assert result.startswith("# Enhanced Test Document")
        assert "This is a test." in result
    
    def test_generate_v2_with_insertions(self, temp_markdown_file):
        """Test that generate_v2 correctly applies insertions."""
        # Create a subclass that overrides collect_issues
        class TestEditor(MockEditor):
            def collect_issues(self) -> None:
                # Do nothing, we'll add issues manually
                pass

        editor = TestEditor(path=temp_markdown_file)

        # Add an insertion issue
        editor.add_insertion(InsertLineIssue(
            line=2,
            insert_content="This is an inserted line."
        ))

        result = editor.generate_v2()

        assert "# Test Document" in result
        assert "This is an inserted line." in result
        assert "This is a test." in result
    
    def test_generate_v2_with_deletions(self, temp_markdown_file):
        """Test that generate_v2 correctly applies deletions."""
        # Create a subclass that overrides collect_issues
        class TestEditor(MockEditor):
            def collect_issues(self) -> None:
                # Do nothing, we'll add issues manually
                pass

        editor = TestEditor(path=temp_markdown_file)

        # Add a deletion issue
        editor.add_deletion(DeleteLineIssue(
            line=3,
            issue_message=["This line should be removed"],
            existing_content="This is a test."
        ))

        result = editor.generate_v2()

        assert "# Test Document" in result
        assert "This is a test." not in result
    
    def test_generate_v2_with_mixed_changes(self, complex_markdown_file, monkeypatch):
        """Test that generate_v2 correctly applies mixed changes (replace, insert, delete)."""
        # Create a subclass that overrides collect_issues
        class TestEditor(MockEditor):
            def collect_issues(self) -> None:
                # Do nothing, we'll add issues manually
                pass

        editor = TestEditor(path=complex_markdown_file)

        # Mock the fix method to return a known value
        def mock_fix(self):
            return "# Improved Sample Document" if self.line == 1 else self.existing_content

        monkeypatch.setattr(ReplaceLineFixableIssue, "fix", mock_fix)

        # Add various issues
        editor.add_replacement(ReplaceLineFixableIssue(
            line=1,
            issue_message=["Title should be more descriptive"],
            existing_content="# Sample Document"
        ))
        editor.add_insertion(InsertLineIssue(
            line=3,
            insert_content="This is a newly inserted line."
        ))
        editor.add_deletion(DeleteLineIssue(
            line=5,
            issue_message=["This section heading should be removed"],
            existing_content="## Section 1"
        ))

        result = editor.generate_v2()

        # Check replacements
        assert "# Improved Sample Document" in result
        assert "# Sample Document" not in result

        # Check insertions
        assert "This is a newly inserted line." in result

        # Check deletions
        assert "## Section 1" not in result

        # Make sure other content is preserved
        assert "This is a test document with **bold** text." in result
        assert "- Item 1" in result
</file>

<file path="tests/unit/editors/test_custom_rules_editor.py">
import pytest
from pathlib import Path
from unittest import mock

from editai.editors.custom_rules import CustomRuleEditor

@pytest.fixture
def rules_directory(tmp_path):
    """Creates a temporary directory with test rule files."""
    rules_dir = tmp_path / "rules"
    rules_dir.mkdir()
    
    # Create test rules
    rule_files = {
        "test_rule.md": "# Test Rule\nReplace 'foo' with 'bar'",
        "passive_voice.md": "# Passive Voice Rule\nConvert passive voice to active voice.\nExample: 'The bug was fixed by the team' → 'The team fixed the bug'",
        "formatting.md": "# Formatting Rule\nEnsure all bullet points end with a period."
    }
    
    for filename, content in rule_files.items():
        rule_file = rules_dir / filename
        rule_file.write_text(content)
    
    yield rules_dir

@pytest.fixture
def sample_markdown_file(tmp_path):
    """Creates a sample markdown file with text for rule application."""
    test_file = tmp_path / "test.md"
    test_file.write_text("""# Test Document

This file contains foo which should be replaced.
The data was processed by the system.

## List of items
- First item
- Second item
- Third item without period
""")
    return test_file


class TestCustomRuleEditor:
    """Tests for the CustomRuleEditor class."""
    
    def test_prerun_checks_success(self, rules_directory, sample_markdown_file):
        """Test prerun_checks with valid directory and rules."""
        editor = CustomRuleEditor(
            path=sample_markdown_file,
            rules_directory=rules_directory
        )
        
        result = editor.prerun_checks()
        
        assert result is True
    
    def test_prerun_checks_nonexistent_directory(self, sample_markdown_file, tmp_path):
        """Test prerun_checks with nonexistent directory."""
        nonexistent_dir = tmp_path / "nonexistent"
        
        editor = CustomRuleEditor(
            path=sample_markdown_file,
            rules_directory=nonexistent_dir
        )
        
        result = editor.prerun_checks()
        
        assert result is False
    
    def test_prerun_checks_empty_directory(self, sample_markdown_file, tmp_path):
        """Test prerun_checks with empty directory."""
        empty_dir = tmp_path / "empty"
        empty_dir.mkdir()
        
        editor = CustomRuleEditor(
            path=sample_markdown_file,
            rules_directory=empty_dir
        )
        
        result = editor.prerun_checks()
        
        assert result is False
    
    def test_load_rules(self, rules_directory, sample_markdown_file):
        """Test _load_rules loads all rule files."""
        editor = CustomRuleEditor(
            path=sample_markdown_file,
            rules_directory=rules_directory
        )
        
        rules = editor._load_rules()
        
        assert len(rules) == 3
        assert "test_rule" in rules
        assert "passive_voice" in rules
        assert "formatting" in rules
        assert "Replace 'foo' with 'bar'" in rules["test_rule"]
        assert "Convert passive voice to active voice" in rules["passive_voice"]
    
    def test_filter_rules_with_include(self, rules_directory, sample_markdown_file):
        """Test _filter_rules with include rules list."""
        editor = CustomRuleEditor(
            path=sample_markdown_file,
            rules_directory=rules_directory,
            include_rules=["test_rule"]
        )
        
        rules = editor._load_rules()
        filtered = editor._filter_rules(rules)
        
        assert len(filtered) == 1
        assert "test_rule" in filtered
        assert "passive_voice" not in filtered
        assert "formatting" not in filtered
    
    def test_filter_rules_with_exclude(self, rules_directory, sample_markdown_file):
        """Test _filter_rules with exclude rules list."""
        editor = CustomRuleEditor(
            path=sample_markdown_file,
            rules_directory=rules_directory,
            exclude_rules=["passive_voice"]
        )
        
        rules = editor._load_rules()
        filtered = editor._filter_rules(rules)
        
        assert len(filtered) == 2
        assert "test_rule" in filtered
        assert "passive_voice" not in filtered
        assert "formatting" in filtered
    
    def test_filter_rules_nonexistent_include(self, rules_directory, sample_markdown_file):
        """Test _filter_rules with nonexistent include rule."""
        editor = CustomRuleEditor(
            path=sample_markdown_file,
            rules_directory=rules_directory,
            include_rules=["nonexistent_rule"]
        )
        
        rules = editor._load_rules()
        filtered = editor._filter_rules(rules)
        
        assert len(filtered) == 0
    
    @mock.patch('editai.editors.custom_rules.fix_line_edit')
    def test_apply_rule(self, mock_fix_line_edit, rules_directory, sample_markdown_file):
        """Test apply_rule with a basic rule."""
        # Mock the fix_line_edit function to return a modified text
        mock_fix_line_edit.return_value = """# Test Document

This file contains bar which should be replaced.
The data was processed by the system.

## List of items
- First item
- Second item
- Third item without period
"""
        
        editor = CustomRuleEditor(
            path=sample_markdown_file,
            rules_directory=rules_directory
        )
        
        rule_content = "# Test Rule\nReplace 'foo' with 'bar'"
        editor.apply_rule(rule_content, "test_rule")
        
        # Check that fix_line_edit was called
        mock_fix_line_edit.assert_called_once()
        
        # Check that changes were recorded
        assert len(editor.deletions) > 0 or len(editor.insertions) > 0
        assert "test_rule" in editor.applied_rules
    
    @mock.patch('editai.editors.custom_rules.fix_line_edit')
    def test_apply_rule_dry_run(self, mock_fix_line_edit, rules_directory, sample_markdown_file):
        """Test apply_rule in dry run mode."""
        mock_fix_line_edit.return_value = """# Test Document

This file contains bar which should be replaced.
The data was processed by the system.

## List of items
- First item
- Second item
- Third item without period
"""
        
        editor = CustomRuleEditor(
            path=sample_markdown_file,
            rules_directory=rules_directory,
            dry_run=True
        )
        
        rule_content = "# Test Rule\nReplace 'foo' with 'bar'"
        editor.apply_rule(rule_content, "test_rule")
        
        # Check that fix_line_edit was called but no changes were recorded
        mock_fix_line_edit.assert_called_once()
        assert len(editor.deletions) == 0
        assert len(editor.insertions) == 0
        assert "test_rule" not in editor.applied_rules
    
    @mock.patch('editai.editors.custom_rules.fix_line_edit')
    def test_process_diff_with_same_line_count(self, mock_fix_line_edit, rules_directory, sample_markdown_file):
        """Test _process_diff with modified lines but same line count."""
        original_lines = ["Line 1", "Line 2", "Line 3"]
        corrected_lines = ["Line 1", "Modified Line 2", "Line 3"]
        
        editor = CustomRuleEditor(
            path=sample_markdown_file,
            rules_directory=rules_directory
        )
        
        editor._process_diff(original_lines, corrected_lines, "test_rule")
        
        # Should have one deletion and one insertion for the changed line
        assert len(editor.deletions) == 1
        assert len(editor.insertions) == 1
        assert editor.deletions[0].line == 2
        assert editor.deletions[0].existing_content == "Line 2"
        assert editor.insertions[0].line == 2
        assert editor.insertions[0].insert_content == "Modified Line 2"
    
    @mock.patch('editai.editors.custom_rules.fix_line_edit')
    def test_process_diff_with_different_line_count(self, mock_fix_line_edit, rules_directory, sample_markdown_file):
        """Test _process_diff with different line counts."""
        original_lines = ["Line 1", "Line 2", "Line 3"]
        corrected_lines = ["Line 1", "Modified Line 2", "Line 3", "New Line 4"]
        
        editor = CustomRuleEditor(
            path=sample_markdown_file,
            rules_directory=rules_directory
        )
        
        editor._process_diff(original_lines, corrected_lines, "test_rule")
        
        # Should delete all original lines and insert all new lines
        assert len(editor.deletions) == 3
        assert len(editor.insertions) == 4
        
        # Check deletion lines
        for i in range(3):
            assert editor.deletions[i].line == i + 1
            assert editor.deletions[i].existing_content == original_lines[i]
        
        # Check insertion lines
        for i in range(4):
            assert editor.insertions[i].line == i + 1
            assert editor.insertions[i].insert_content == corrected_lines[i]
    
    @mock.patch('editai.editors.custom_rules.fix_line_edit')
    def test_collect_issues(self, mock_fix_line_edit, rules_directory, sample_markdown_file):
        """Test collect_issues loads and applies rules."""
        # Mock the fix_line_edit function for each rule
        def side_effect(line_edit, content):
            # Simple replacement based on rule name
            if "test_rule" in str(line_edit.issue_message):
                return content.replace("foo", "bar")
            elif "passive_voice" in str(line_edit.issue_message):
                return content.replace("was processed by", "processed")
            elif "formatting" in str(line_edit.issue_message):
                return content.replace("Third item without period", "Third item without period.")
            return content
            
        mock_fix_line_edit.side_effect = side_effect
        
        editor = CustomRuleEditor(
            path=sample_markdown_file,
            rules_directory=rules_directory
        )
        
        editor.collect_issues()
        
        # Should have called fix_line_edit for each rule
        assert mock_fix_line_edit.call_count == 3
        
        # Check that all rules were applied
        assert len(editor.applied_rules) == 3
        assert set(editor.applied_rules) == {"test_rule", "passive_voice", "formatting"}
    
    @mock.patch('editai.editors.custom_rules.fix_line_edit')
    def test_generate_v2(self, mock_fix_line_edit, rules_directory, sample_markdown_file):
        """Test generate_v2 applies all rules and returns modified content."""
        # Read the original content
        with open(sample_markdown_file, "r") as f:
            original_content = f.read()
        
        # Mock the fix_line_edit function
        mock_fix_line_edit.return_value = """# Test Document

This file contains bar which should be replaced.
The system processed the data.

## List of items
- First item.
- Second item.
- Third item without period.
"""
        
        editor = CustomRuleEditor(
            path=sample_markdown_file,
            rules_directory=rules_directory,
            include_rules=["test_rule"]  # Only use one rule for simplicity
        )
        
        result = editor.generate_v2()
        
        # Check that the content was modified
        assert result != original_content
        assert "bar" in result
        assert "foo" not in result
</file>

<file path="tests/unit/test_cli.py">
import pytest
from pathlib import Path
from typer.testing import CliRunner
from unittest import mock

from editai.cli import app


@pytest.fixture
def runner():
    """Create a CLI runner for testing."""
    return CliRunner()


class TestCLI:
    """Tests for the CLI commands."""
    
    @mock.patch('editai.cli.ValeEditor')
    @mock.patch('editai.cli.get_vale_config_path')
    def test_vale_single_file(self, mock_get_vale_config_path, mock_vale_editor, runner, tmp_path):
        """Test the vale command with a single file."""
        # Create a test file
        test_file = tmp_path / "test.md"
        test_file.write_text("# Test Document")

        # Mock the Vale config path
        mock_vale_config_path = tmp_path / ".vale.ini"
        mock_get_vale_config_path.return_value = mock_vale_config_path

        # Mock the editor
        mock_instance = mock_vale_editor.return_value
        mock_instance.generate_v2.return_value = "# Test Document (Fixed)"

        # Run the command
        result = runner.invoke(app, ['vale', str(test_file)])

        # Check the result
        assert result.exit_code == 0
        assert "Processed file" in result.stdout

        # Verify the editor was called correctly
        mock_vale_editor.assert_called_once()
        mock_instance.generate_v2.assert_called_once()
    
    @mock.patch('editai.cli.ValeEditor')
    @mock.patch('editai.cli.FolderProcessor')
    @mock.patch('editai.cli.get_vale_config_path')
    def test_vale_directory(self, mock_get_vale_config_path, mock_folder_processor, mock_vale_editor, runner, tmp_path):
        """Test the vale command with a directory."""
        # Create a test directory
        test_dir = tmp_path / "test_dir"
        test_dir.mkdir()

        # Mock the Vale config path
        mock_vale_config_path = tmp_path / ".vale.ini"
        mock_get_vale_config_path.return_value = mock_vale_config_path

        # Mock the folder processor
        mock_processor_instance = mock_folder_processor.return_value
        mock_processor_instance.process_directory.return_value = {
            "file1.md": "content1",
            "file2.md": "content2"
        }

        # Run the command
        result = runner.invoke(app, ['vale', str(test_dir)])

        # Check the result
        assert result.exit_code == 0
        assert "Processed 2 files" in result.stdout

        # Verify the folder processor was called correctly
        mock_folder_processor.assert_called_once()
        mock_processor_instance.process_directory.assert_called_once_with(dry_run=False)
    
    @mock.patch('editai.cli.ValeEditor')
    @mock.patch('editai.cli.get_vale_config_path')
    def test_vale_dry_run(self, mock_get_vale_config_path, mock_vale_editor, runner, tmp_path):
        """Test the vale command with dry run option."""
        # Create a test file
        test_file = tmp_path / "test.md"
        test_file.write_text("# Test Document")

        # Mock the Vale config path
        mock_vale_config_path = tmp_path / ".vale.ini"
        mock_get_vale_config_path.return_value = mock_vale_config_path

        # Mock the editor
        mock_instance = mock_vale_editor.return_value
        mock_instance.generate_v2.return_value = "# Test Document (Fixed)"

        # Run the command with dry run
        result = runner.invoke(app, ['vale', str(test_file), '--dry-run'])

        # Check the result
        assert result.exit_code == 0
        assert "Dry run - would update" in result.stdout
        assert "# Test Document (Fixed)" in result.stdout
    
    @mock.patch('editai.cli.AIEditor')
    def test_ai_single_file(self, mock_ai_editor, runner, tmp_path):
        """Test the ai command with a single file."""
        # Create a test file
        test_file = tmp_path / "test.md"
        test_file.write_text("# Test Document")
        
        # Mock the editor
        mock_instance = mock_ai_editor.return_value
        mock_instance.generate_v2.return_value = "# Test Document (Enhanced)"
        
        # Run the command
        result = runner.invoke(app, ['ai', str(test_file)])
        
        # Check the result
        assert result.exit_code == 0
        assert "Processed file" in result.stdout
        
        # Verify the editor was called correctly
        mock_ai_editor.assert_called_once()
        mock_instance.generate_v2.assert_called_once()
    
    @mock.patch('editai.cli.AIEditor')
    @mock.patch('editai.cli.FolderProcessor')
    def test_ai_directory(self, mock_folder_processor, mock_ai_editor, runner, tmp_path):
        """Test the ai command with a directory."""
        # Create a test directory
        test_dir = tmp_path / "test_dir"
        test_dir.mkdir()
        
        # Mock the folder processor
        mock_processor_instance = mock_folder_processor.return_value
        mock_processor_instance.process_directory.return_value = {
            "file1.md": "content1",
            "file2.md": "content2",
            "file3.md": "content3"
        }
        
        # Run the command
        result = runner.invoke(app, ['ai', str(test_dir), '--recursive'])
        
        # Check the result
        assert result.exit_code == 0
        assert "Processed 3 files" in result.stdout
        
        # Verify the folder processor was called correctly
        mock_folder_processor.assert_called_once_with(
            directory_path=Path(str(test_dir)), 
            editor_class=mock_ai_editor,
            editor_kwargs={},
            include_pattern="*.md",
            exclude_patterns=[],
            recursive=True
        )
    
    @mock.patch('editai.cli.CustomRuleEditor')
    def test_custom_rules_single_file(self, mock_custom_rule_editor, runner, tmp_path):
        """Test the custom-rules command with a single file."""
        # Create a test file and rules directory
        test_file = tmp_path / "test.md"
        test_file.write_text("# Test Document")
        
        rules_dir = tmp_path / "rules"
        rules_dir.mkdir()
        (rules_dir / "rule1.md").write_text("# Rule 1")
        
        # Mock the editor
        mock_instance = mock_custom_rule_editor.return_value
        mock_instance.generate_v2.return_value = "# Test Document (With Rules Applied)"
        
        # Run the command
        result = runner.invoke(app, [
            'custom-rules', 
            str(test_file), 
            str(rules_dir), 
            '--include-rules', 'rule1'
        ])
        
        # Check the result
        assert result.exit_code == 0
        assert "Processed file" in result.stdout
        
        # Verify the editor was called correctly
        mock_custom_rule_editor.assert_called_once_with(
            path=Path(str(test_file)),
            rules_directory=Path(str(rules_dir)),
            include_rules=['rule1'],
            exclude_rules=[],
            dry_run=False
        )
        mock_instance.generate_v2.assert_called_once()
    
    def test_list_rules(self, runner, tmp_path):
        """Test the list-rules command."""
        # Create a test rules directory with some rule files
        rules_dir = tmp_path / "rules"
        rules_dir.mkdir()
        (rules_dir / "rule1.md").write_text("# Rule 1")
        (rules_dir / "rule2.md").write_text("# Rule 2")
        (rules_dir / "rule3.md").write_text("# Rule 3")
        
        # Run the command
        result = runner.invoke(app, ['list-rules', str(rules_dir)])
        
        # Check the result
        assert result.exit_code == 0
        assert "Found 3 rules" in result.stdout
        assert "- rule1" in result.stdout
        assert "- rule2" in result.stdout
        assert "- rule3" in result.stdout
    
    def test_view_rule(self, runner, tmp_path):
        """Test the view-rule command."""
        # Create a test rules directory with a rule file
        rules_dir = tmp_path / "rules"
        rules_dir.mkdir()
        (rules_dir / "test_rule.md").write_text("# Test Rule\nThis is a test rule.")
        
        # Run the command
        result = runner.invoke(app, ['view-rule', str(rules_dir), 'test_rule'])
        
        # Check the result
        assert result.exit_code == 0
        assert "--- Rule: test_rule ---" in result.stdout
        assert "This is a test rule." in result.stdout
    
    def test_create_rule(self, runner, tmp_path):
        """Test the create-rule command."""
        # Create a test rules directory
        rules_dir = tmp_path / "rules"
        rules_dir.mkdir()
        
        # Run the command
        result = runner.invoke(app, ['create-rule', str(rules_dir), 'new_rule'])
        
        # Check the result
        assert result.exit_code == 0
        assert "Created rule" in result.stdout
        
        # Verify the file was created
        new_rule_path = rules_dir / "new_rule.md"
        assert new_rule_path.exists()
        assert "Rule: new_rule" in new_rule_path.read_text()
    
    @mock.patch('editai.cli.ArbitraryLinkEditor')
    def test_arbitrary_links(self, mock_arbitrary_link_editor, runner, tmp_path):
        """Test the arbitrary-links command."""
        # Create a test file
        test_file = tmp_path / "test.md"
        test_file.write_text("# Test Document")
        
        # Mock the editor
        mock_instance = mock_arbitrary_link_editor.return_value
        mock_instance.generate_v2.return_value = "# Test Document with Links"
        
        # Run the command
        result = runner.invoke(app, ['arbitrary-links', str(test_file)])
        
        # Check the result
        assert result.exit_code == 0
        assert "# Test Document with Links" in result.stdout
        
        # Verify the editor was called correctly
        mock_arbitrary_link_editor.assert_called_once_with(path=Path(str(test_file)))
        mock_instance.generate_v2.assert_called_once()
    
    def test_arbitrary_links_directory_error(self, runner, tmp_path):
        """Test the arbitrary-links command with directory path."""
        # Create a test directory
        test_dir = tmp_path / "test_dir"
        test_dir.mkdir()
        
        # Run the command with a directory path
        result = runner.invoke(app, ['arbitrary-links', str(test_dir)])
        
        # Check that it fails appropriately
        assert result.exit_code == 1
        assert "doesn't support directory processing" in result.stdout
    
    @mock.patch('editai.cli.InternalLinkEditor')
    def test_links_with_indexes(self, mock_internal_link_editor, runner, tmp_path):
        """Test the links command with index names."""
        # Create a test file
        test_file = tmp_path / "test.md"
        test_file.write_text("# Test Document")
        
        # Mock the editor
        mock_instance = mock_internal_link_editor.return_value
        mock_instance.generate_v2.return_value = "# Test Document with Internal Links"
        
        # Run the command with index names
        result = runner.invoke(app, [
            'links', 
            str(test_file), 
            '--local-index-names', 'index1,index2'
        ])
        
        # Check the result
        assert result.exit_code == 0
        assert "Processed file" in result.stdout
        
        # Verify the editor was called correctly
        mock_internal_link_editor.assert_called_once_with(
            path=Path(str(test_file)),
            indexes=['index1', 'index2']
        )
        mock_instance.generate_v2.assert_called_once()
    
    @mock.patch('editai.cli.ImageAdditionEditor')
    def test_add_images(self, mock_image_editor, runner, tmp_path):
        """Test the add-images command."""
        # Create a test file and image directory
        test_file = tmp_path / "test.md"
        test_file.write_text("# Test Document")
        
        image_dir = tmp_path / "images"
        image_dir.mkdir()
        
        # Mock the editor
        mock_instance = mock_image_editor.return_value
        mock_instance.generate_v2.return_value = "# Test Document with Images"
        
        # Run the command
        result = runner.invoke(app, [
            'add-images', 
            str(test_file), 
            str(image_dir), 
            '--image-url-prefix', '/custom/images'
        ])
        
        # Check the result
        assert result.exit_code == 0
        assert "Processed file" in result.stdout
        
        # Verify the editor was called correctly
        mock_image_editor.assert_called_once_with(
            path=Path(str(test_file)),
            image_folder_path=Path(str(image_dir)),
            image_url_prefix='/custom/images'
        )
        mock_instance.generate_v2.assert_called_once()
</file>

<file path="tests/conftest.py">
import pytest
import tempfile
from pathlib import Path

@pytest.fixture
def temp_markdown_file():
    """Creates a temporary markdown file for testing and cleans it up after the test."""
    with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
        f.write("# Test Document\n\nThis is a test.")
        temp_path = Path(f.name)
    yield temp_path
    temp_path.unlink()

@pytest.fixture
def mock_ai_response():
    """Returns a mock AI response with line edits."""
    return {
        "line_edits": [
            {
                "starting_affected_line": 1,
                "ending_affected_line": 1,
                "issue_message": "Test issue",
                "resolution": "edit",
                "new_lines": ["# Test Document (Edited)"]
            }
        ]
    }

@pytest.fixture
def complex_markdown_file():
    """Creates a more complex temporary markdown file for testing."""
    with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
        f.write("""# Sample Document

This is a test document with **bold** text.

## Section 1
- Item 1
- Item 2

Here's some code:
```python
print("Hello")
```
""")
        temp_path = Path(f.name)
    yield temp_path
    temp_path.unlink()
</file>

<file path="tests/README.md">
# EditAI Tests

This directory contains tests for the EditAI project.

## Current Test Coverage

The current test suite covers the following components:

| Component | Coverage | Status |
|-----------|----------|--------|
| BaseEditor | 84% | ✅ Good |
| AIEditor | 81% | ✅ Good |
| CustomRuleEditor | 91% | ✅ Excellent |
| FolderProcessor | 76% | ✅ Good |
| CLI | 73% | ✅ Good |
| ArbitraryLinkEditor | 32% | ❌ Needs improvement |
| ImageAdditionEditor | 20% | ❌ Needs improvement |
| LinkEditor | 31% | ❌ Needs improvement |
| ValeEditor | 39% | ❌ Needs improvement |
| Utils | 17% | ❌ Needs improvement |

Overall coverage: 53%

## Test Structure

- `tests/test_folder_processor.py` - Tests for folder processing functionality
- `tests/unit/` - Unit tests for individual components
  - `tests/unit/editors/` - Tests for editor implementations
  - `tests/unit/test_cli.py` - Tests for CLI commands

## Running Tests

To run all tests:
```bash
pytest
```

To run tests with coverage:
```bash
pytest --cov=editai tests/
```

To generate a coverage report:
```bash
pytest --cov=editai --cov-report=html tests/
```

## Test Dependencies

Test dependencies are defined in `pyproject.toml` under `project.optional-dependencies.test`.

To install dependencies:
```bash
uv pip install -e ".[test]"
```

## Next Steps

### High Priority

1. Add tests for ArbitraryLinkEditor
2. Add tests for ImageAdditionEditor 
3. Add tests for LinkEditor
4. Add tests for ValeEditor
5. Improve tests for utility functions

### Medium Priority

1. Add integration tests for complete workflows
2. Add tests for error handling and edge cases
3. Improve CLI test coverage

### Low Priority

1. Add performance tests
2. Add property-based tests with hypothesis
3. Set up CI/CD pipeline with GitHub Actions
</file>

<file path="docs/folder_processing.md">
# Folder Processing in Tutedit

Tutedit now supports processing multiple files in a directory using a single command.

## Overview

The folder processing feature allows you to run any of the document editing tools on all markdown files in a directory, rather than processing them one at a time. This is useful for:

- Applying consistent style rules across a documentation set
- Adding internal links across multiple related documents
- Performing AI-based improvements on all documentation files
- Adding images to all documents in a folder

## Usage

Most commands now detect whether the `path` parameter is a file or a directory. If it's a directory, the command will process all markdown files within that directory.

### Example Commands

```bash
# Apply custom rules to all markdown files in a directory
tutedit custom-rules ./docs/ ./rules/ --recursive

# Use AI to improve all markdown files in a directory
tutedit ai ./docs/ --recursive --include-pattern "*.md" --exclude-patterns "_drafts/*.md"

# Add internal links to all markdown files in a directory
tutedit links ./docs/ --local-index-names docs-index --recursive

# Run Vale on all markdown files in a directory
tutedit vale ./docs/ --vale-config-path ./.vale.ini --recursive
```

## Common Parameters

The following parameters are supported by all commands that accept directory paths:

- `--recursive`: Process subdirectories recursively (default: False)
- `--include-pattern`: Glob pattern for files to include (default: "*.md")
- `--exclude-patterns`: List of glob patterns for files to exclude
- `--dry-run`: Don't modify files, just show what would be changed

## Command-Specific Notes

### Arbitrary Links Editor

The `arbitrary-links` command does not support directory processing since it's an interactive command that requires user input for each document.

### Custom Rules Editor

When using `custom-rules` on a directory, you can still use the `--include-rules` and `--exclude-rules` parameters to control which rules are applied. These parameters are separate from the `--include-pattern` and `--exclude-patterns` parameters that control which files are processed.

## Best Practices

1. **Always use `--dry-run` first**: Before applying changes to multiple files, use the `--dry-run` option to see what changes would be made.

2. **Use `--include-pattern` and `--exclude-patterns`**: Narrow down the files to be processed to avoid changing files you don't intend to modify.

3. **Start with non-recursive mode**: Until you're comfortable with the behavior, avoid using `--recursive` to limit the scope of changes.

4. **Consider processing time**: Some editors, particularly the AI editor, may take significant time to process large numbers of files.

## Examples

### Process all markdown files in a directory recursively

```bash
tutedit custom-rules ./docs/ ./rules/ --recursive --dry-run
```

### Process only files in a specific pattern

```bash
tutedit ai ./guides/ --include-pattern "getting-started*.md"
```

### Exclude certain files or directories

```bash
tutedit vale ./docs/ --exclude-patterns "_drafts/*.md,internal/*.md" --recursive
```

### Process a nested directory structure

```bash
tutedit links ./documentation/ --recursive --exclude-patterns "assets/*,images/*,_templates/*"
```
</file>

<file path="examples/folder_processing/subfolder/doc3.md">
# Example Document 3 (Subfolder)

## Nested Passive Voice Examples

The test was performed by the QA team. The approval was granted by the committee. The feature was requested by the customer.

Multiple issues were resolved in the update. The cache was cleared by the application. The logs were compressed for storage.

## Nested Bullet Point Inconsistency

Requirements for the system:
* minimum 8GB RAM
* Compatible with Linux
* the CPU must be 64-bit
* supports virtualization

Configuration options:
* enable debug mode
* Setting memory limits
* disable caching
* Export configurations.
</file>

<file path="examples/folder_processing/doc1.md">
# Example Document 1

## Passive Voice Example

The data was processed by our system. The results are being generated as we speak. The analysis has been completed by the team.

Several issues were identified during the review. The bug has been fixed by the developers. The feature was implemented in the latest release.

## Bullet Point Inconsistency

Benefits of our product:
* saves time
* Improving efficiency
* the cost is reduced.
* makes workflows smoother

Features to explore:
* Add new users
* editing documents
* share with team
* Export to PDF.
</file>

<file path="examples/folder_processing/doc2.md">
# Example Document 2

## More Passive Voice Examples

The error was caught by the exception handler. A timeout was triggered by the API. The issue was reported by several users.

Multiple warnings were displayed on the console. The configuration file was generated automatically. The data was imported from a CSV file.

## More Bullet Point Inconsistency

Advantages of this approach:
* faster processing
* Better memory usage
* the errors are reduced
* works consistently

Steps to follow:
* install the package
* Configuring the settings
* run the application
* Review results.
</file>

<file path="examples/folder_processing/README.md">
# Folder Processing Example

This directory contains example files for testing the folder processing functionality.

## Contents

- `doc1.md` - Example document with passive voice and bullet point inconsistencies
- `doc2.md` - Second example document with more passive voice and bullet point inconsistencies
- `subfolder/doc3.md` - Nested example document to test recursive processing

## Testing Commands

You can test folder processing with the following commands:

### Process all files recursively

```bash
python -m tutedit.cli custom-rules ./examples/folder_processing/ ./test_rules/ --recursive --dry-run
```

### Process only top-level files

```bash
python -m tutedit.cli custom-rules ./examples/folder_processing/ ./test_rules/ --dry-run
```

### Process specific files by pattern

```bash
python -m tutedit.cli custom-rules ./examples/folder_processing/ ./test_rules/ --include-pattern "doc1*.md" --dry-run
```

### Exclude subfolder

```bash
python -m tutedit.cli custom-rules ./examples/folder_processing/ ./test_rules/ --exclude-patterns "subfolder/*" --recursive --dry-run
```

### Apply only specific rules

```bash
python -m tutedit.cli custom-rules ./examples/folder_processing/ ./test_rules/ --include-rules passive_voice --recursive --dry-run
```

## Expected Results

When applying the custom rules to these files, you should see:

1. Passive voice sentences converted to active voice
2. Bullet points consistently formatted (capitalized and with appropriate punctuation)

Remove the `--dry-run` flag to actually apply the changes to the files.
</file>

<file path="src/editai/editors/__init__.py">
from .ai import AIEditor
from .arbitrary_links import ArbitraryLinkEditor
from .core import BaseEditor
from .custom_rules import CustomRuleEditor
from .folder_processor import FolderProcessor
from .images import ImageAdditionEditor
from .links import InternalLinkEditor
from .vale import ValeEditor
</file>

<file path="src/editai/editors/ai.py">
import os
from typing import List, Literal, Optional

import diskcache  # type: ignore
import instructor
from litellm import completion
from loguru import logger
from pydantic import BaseModel, Field

from .core import BaseEditor, DeleteLineIssue, InsertLineIssue

# Constants
# Use a separate cache directory for this editor
cache = diskcache.Cache("./data/cache/ai_editor")
patched_client = instructor.from_litellm(completion=completion)

MODEL_NAME = os.getenv("AI_EDITOR_MODEL", "openai/o3-mini-2025-01-31")


class LineEdit(BaseModel):
    """Represents a single identified issue and proposed resolution for a range of lines."""

    starting_affected_line: int = Field(
        description="The 1-indexed starting line number of the text block with the issue."
    )
    ending_affected_line: int = Field(
        description="The 1-indexed ending line number of the text block with the issue."
    )
    issue_message: str = Field(
        description="A concise description of the identified issue (e.g., 'Inconsistent formatting', 'Redundant explanation', 'Awkward phrasing')."
    )
    resolution: Literal["edit", "delete", "flag"] = Field(
        description=(
            "The suggested resolution: 'edit' to modify the text, "
            "'delete' to remove the text block, "
            "'flag' to report the issue without automated changes (e.g., for complex errors or code blocks)."
        )
    )


class LineEdits(BaseModel):
    """A collection of line edits identified in the text."""

    line_edits: List[LineEdit] = Field(
        description="A list of identified issues and their proposed resolutions."
    )


class CorrectedText(BaseModel):
    """Represents the corrected text block."""

    corrected_text: str = Field(
        description="The corrected version of the text block provided."
    )


def get_line_edits(text_with_line_numbers: str) -> LineEdits:
    """Identifies potential issues in the text using an AI model.

    Args:
        text_with_line_numbers: The input text, with each line prefixed by its number.

    Returns:
        A LineEdits object containing the identified issues.
    """
    prompt = f"""You are an expert technical editor reviewing a document.

    Your task is to identify sections of the text that could be improved for clarity, conciseness, consistency, or formatting. Focus on improving the flow and readability for a technical audience.

    Here is the text with line numbers:
    <text>
    {text_with_line_numbers}
    </text>

    Identify issues and suggest a resolution for each:
    - 'edit': If the text can be clearly improved (e.g., fixing typos, rephrasing awkward sentences, correcting minor formatting). Provide a concise 'issue_message'.
    - 'delete': If a block of text (one or more lines) is redundant, unnecessary, or clearly erroneous and should be removed.
    - 'flag': If there's a significant issue you can identify but cannot confidently fix (e.g., missing information, a potentially incorrect technical statement, complex formatting problems, issues within code blocks). Use 'flag' for anything inside ``` blocks.

    Provide the starting and ending line number for each identified issue.
    Ensure the line ranges are accurate and cover the entire relevant text block for the issue.

    Return a list of identified issues and their resolutions.
    """
    try:
        logger.info(f"Requesting line edits using model: {MODEL_NAME}")
        response: LineEdits = patched_client.chat.completions.create(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": prompt}],
            response_model=LineEdits,
            max_tokens=2048,  # Allow for potentially many edits
        )
        logger.success(
            f"Received {len(response.line_edits)} potential line edits from AI."
        )
        return response
    except Exception as e:
        logger.error(f"Error getting line edits from AI: {e}", exc_info=True)
        # Return empty list on error
        return LineEdits(line_edits=[])


def fix_line_edit(line_edit: LineEdit, relevant_lines: str) -> Optional[str]:
    """Generates corrected text for a given line edit using an AI model.

    Args:
        line_edit: The LineEdit object describing the issue.
        relevant_lines: The specific lines of text affected by the edit.

    Returns:
        The corrected text block as a single string, or None if correction fails.
    """
    prompt = f"""You are an expert technical editor tasked with fixing an issue in a specific text block.

    The identified issue is:
    <issue_message>
    {line_edit.issue_message}
    </issue_message>

    Here is the original text block (from line {line_edit.starting_affected_line} to {line_edit.ending_affected_line}):
    <original_text>
    {relevant_lines}
    </original_text>

    Your goal is to rewrite the original text block to resolve *only* the specified issue.
    - Maintain the original meaning and intent unless the issue is about factual correctness.
    - Preserve the original line breaks and indentation as much as possible, unless the issue is specifically about formatting.
    - Ensure the corrected text seamlessly fits back into the surrounding document.
    - ONLY return the corrected text block itself, without any extra explanations or formatting.

    Return the corrected text block.
    """
    try:
        logger.info(
            f"Requesting fix for lines {line_edit.starting_affected_line}-{line_edit.ending_affected_line} using model: {MODEL_NAME}"
        )
        # Using CorrectedText response model for structure, although the prompt asks for raw text.
        # This adds a layer of validation.
        response: CorrectedText = patched_client.chat.completions.create(
            model="anthropic/claude-3-haiku-20240307",
            messages=[{"role": "user", "content": prompt}],
            response_model=CorrectedText,
            max_tokens=1024,  # Should be enough for typical block edits
        )
        logger.success(
            f"Received corrected text for lines {line_edit.starting_affected_line}-{line_edit.ending_affected_line}."
        )
        return (
            response.corrected_text.strip()
        )  # Strip potential leading/trailing whitespace
    except Exception as e:
        logger.error(
            f"Error fixing line edit for lines {line_edit.starting_affected_line}-{line_edit.ending_affected_line}: {e}",
            exc_info=True,
        )
        return None  # Return None on error


# TODO: Implement AIEditor class inheriting from BaseEditor
class AIEditor(BaseEditor):
    """
    Editor that uses AI to identify and fix issues related to
    clarity, conciseness, consistency, and formatting in text.
    It can suggest edits, deletions, or flag issues for manual review.
    """

    def _fetch_line_edits(self) -> LineEdits:
        """Fetches or retrieves cached line edits for the current text."""

        logger.debug("Fetching line edits from AI...")
        text_with_line_numbers = self.get_text_with_line_numbers()  # Use helper
        # Use the configured model for detection
        return get_line_edits(text_with_line_numbers)

    def prerun_checks(self) -> bool:
        """Basic checks before running the editor."""
        # Could add checks for API keys if needed, but LiteLLM handles env vars
        logger.success("AI Editor prerun checks passed.")
        return True

    def collect_issues(self) -> None:
        """Collects issues identified by AI and translates them into insertions/deletions."""
        line_edits_response = self._fetch_line_edits()
        line_lookup = self.get_line_number_lookup()
        processed_lines = set()  # Track lines involved in an operation
        insertions_count = 0
        deletions_count = 0
        flagged_count = 0

        # Sort edits by starting line to process potentially overlapping edits predictably
        sorted_edits = sorted(
            line_edits_response.line_edits, key=lambda le: le.starting_affected_line
        )

        for line_edit in sorted_edits:
            start = line_edit.starting_affected_line
            end = line_edit.ending_affected_line
            resolution = line_edit.resolution
            issue_desc = f"AI {resolution.capitalize()}: {line_edit.issue_message}"

            # Validate line numbers against the original lookup
            if not (start in line_lookup and end in line_lookup and start <= end):
                logger.error(
                    f"Invalid line numbers ({start}-{end}) in line edit: {line_edit.issue_message}. Skipping."
                )
                continue

            # Check for overlap with already processed lines
            current_range = set(range(start, end + 1))
            if not current_range.isdisjoint(processed_lines):
                logger.warning(
                    f"Skipping line edit for lines {start}-{end} due to overlap with a previous edit: {line_edit.issue_message}"
                )
                continue

            # Mark lines as processed
            processed_lines.update(current_range)

            if resolution == "edit":
                # Extract relevant lines
                relevant_lines_list = [line_lookup[i] for i in range(start, end + 1)]
                relevant_lines_text = "\n".join(relevant_lines_list)

                # Get the fix from AI
                corrected_text = fix_line_edit(line_edit, relevant_lines_text)

                if corrected_text is not None:
                    if corrected_text.strip():  # Non-empty correction
                        corrected_lines = corrected_text.splitlines()

                        # 1. Add insertions for the corrected lines (inserted before original start)
                        for i, line_content in enumerate(corrected_lines):
                            # Insert each new line before the original start line.
                            # The BaseEditor process logic handles sequential insertions.
                            self.add_insertion(
                                InsertLineIssue(line=start, insert_content=line_content)
                            )
                            insertions_count += 1
                        logger.info(
                            f"Added {len(corrected_lines)} insertions for AI edit at lines {start}-{end}"
                        )

                        # 2. Add deletions for the original lines
                        for line_num in range(start, end + 1):
                            self.add_deletion(
                                DeleteLineIssue(
                                    line=line_num,
                                    existing_content=line_lookup[line_num],
                                    issue_message=[
                                        f"AI Edit (Deleting original line): {line_edit.issue_message}"
                                    ],
                                )
                            )
                            deletions_count += 1
                        logger.info(
                            f"Added {end - start + 1} deletions for AI edit at lines {start}-{end}"
                        )

                    else:  # Empty correction -> Treat as delete
                        logger.warning(
                            f"AI returned empty correction for lines {start}-{end}. Treating as 'delete'."
                        )
                        resolution = "delete"  # Fall through to delete logic
                else:  # Failed to get correction -> Treat as flag
                    logger.error(
                        f"Failed to get AI correction for lines {start}-{end}. Treating as 'flag'."
                    )
                    resolution = "flag"  # Fall through to flag logic

            if resolution == "delete":
                for line_num in range(start, end + 1):
                    self.add_deletion(
                        DeleteLineIssue(
                            line=line_num,
                            existing_content=line_lookup[line_num],
                            issue_message=[issue_desc],
                        )
                    )
                    deletions_count += 1
                logger.info(
                    f"Added {end - start + 1} deletions for AI delete at lines {start}-{end}"
                )

            if resolution == "flag":
                logger.warning(
                    f"Flagged by AI: Lines {start}-{end}: {line_edit.issue_message}"
                )
                flagged_count += 1
                # Optionally add to a separate list or file if needed

        logger.success(
            f"AI Editor finished collecting issues: {insertions_count} insertions, {deletions_count} deletions, {flagged_count} flagged."
        )
</file>

<file path="src/editai/editors/arbitrary_links.py">
from typing import List, Optional

import diskcache
import instructor
from litellm import completion
from loguru import logger
from pydantic import BaseModel, Field, HttpUrl

from .core import BaseEditor, LineIssue, ReplaceLineFixableIssue

cache = diskcache.Cache("./data/cache/editing")
patched_client = instructor.from_litellm(completion=completion)


class ArbitraryLink(BaseModel):
    """A link to be inserted into the text."""

    url: HttpUrl = Field(description="The URL to link to")
    description: str = Field(description="Description of what this link points to")


class LinkPlacement(BaseModel):
    """A suggested placement for a link in the text."""

    line_number: int = Field(
        description="The line number where the link should be placed"
    )
    original_text: str = Field(description="The original line text")
    reasoning: str = Field(description="Reasoning for why this is a good placement")


class LinkRewrite(BaseModel):
    """A rewritten line with a link inserted."""

    rewritten_text: str = Field(
        description="The line rewritten to include the link in a natural way"
    )


class ArbitraryLinkEditor(BaseEditor):
    """Editor for interactively inserting arbitrary links provided by the user."""

    def prerun_checks(self) -> bool:
        # No specific pre-run checks needed
        return True

    def collect_issues(self) -> None:
        """Run the REPL to collect links and find placements."""
        self.run_link_repl()

    def run_link_repl(self) -> None:
        """Run the interactive REPL for entering links."""
        print("=== Arbitrary Link Editor REPL ===")
        print("Enter links to add to your document. Type 'exit' to finish.")

        text_with_line_numbers = self.get_text_with_line_numbers()
        line_lookup = self.get_line_number_lookup()

        while True:
            # Get user input for link
            link_url = input("\nEnter link URL (or 'exit' to finish): ")
            if link_url.lower() == "exit":
                break

            # Get description
            description = input("Enter link description: ")

            try:
                # Create link object
                link = ArbitraryLink(url=link_url, description=description)

                # Find placement for the link
                placement = self.find_link_placement(link, text_with_line_numbers)

                if placement and placement.line_number in line_lookup:
                    # Show placement to user
                    print(f"\nSuggested placement at line {placement.line_number}:")
                    print(f"Original: {placement.original_text}")
                    print(f"Reasoning: {placement.reasoning}")

                    # Confirm with user
                    confirm = input("Apply this link placement? (y/n): ")
                    if confirm.lower() == "y":
                        # Create a replacement issue
                        self.add_replacement_for_link(link, placement, line_lookup)
                        print("Link placement added.")
                    else:
                        print("Link placement skipped.")
                else:
                    print("No suitable placement found for this link.")
            except Exception as e:
                logger.error(f"Error processing link: {e}")
                print(f"Error: {e}")

    def find_link_placement(
        self, link: ArbitraryLink, text_with_line_numbers: str
    ) -> Optional[LinkPlacement]:
        """Find the best placement for a link in the document."""
        prompt = f"""You are an expert technical writer.
        
        You are given a link URL and description, and text with line numbers.
        
        Your job is to find the best location in the text to place this link naturally.
        
        <text_with_line_numbers>
        {text_with_line_numbers}
        </text_with_line_numbers>
        
        <link>
        URL: {link.url}
        Description: {link.description}
        </link>
        
        Find the single best line where this link would be most relevant and helpful.
        The link should enhance the reader's understanding and be placed naturally in the text.
        You must only point to lines of text, not code lines or empty lines.
        NEVER MODIFY CODE LINES.
        
        Return your response as a JSON with the following structure:
        {{
          "line_number": The line number to place the link (as an integer),
          "original_text": "The original text of that line",
          "reasoning": "Why this is a good placement for the link"
        }}
        """

        # Use AI to find placement
        try:
            response = patched_client.chat.completions.create(
                model="claude-3-haiku-20240307",
                max_tokens=1000,
                temperature=0.25,
                messages=[{"role": "user", "content": prompt}],
                response_model=LinkPlacement,
            )
            # Ensure line_number is an integer
            if isinstance(response.line_number, str):
                try:
                    response.line_number = int(response.line_number)
                except ValueError:
                    logger.error(
                        f"Invalid line number returned: {response.line_number}"
                    )
                    return None

            logger.info(f"Found link placement at line {response.line_number}")
            return response
        except Exception as e:
            logger.exception("Error finding link placement", error=e)
            return None

    def add_replacement_for_link(
        self, link: ArbitraryLink, placement: LinkPlacement, line_lookup: dict
    ) -> None:
        """Create a replacement issue for the link placement."""
        # Generate replacement text with link inserted
        rewritten_text = self.generate_link_insertion(link, placement.original_text)

        # Create ReplaceLineFixableIssue with custom rewritten text
        issue = ReplaceLineFixableIssue(
            line=placement.line_number,
            issue_message=[
                f"Insert link to {link.url} described as: {link.description}"
            ],
            existing_content=placement.original_text,
        )

        # Override the fix method to return our rewritten text directly
        original_fix = issue.fix
        issue.fix = lambda: rewritten_text

        self.add_replacement(issue)
        logger.success(f"Added replacement for line {placement.line_number}")

    @cache.memoize()
    def generate_link_insertion(self, link: ArbitraryLink, original_text: str) -> str:
        """Generate a rewritten line with the link naturally inserted."""
        prompt = f"""You are an expert technical writer.
        
        You need to rewrite this line to naturally include a link in Markdown format.
        
        <original_line>
        {original_text}
        </original_line>
        
        <link>
        URL: {link.url}
        Description: {link.description}
        </link>
        
        Rewrite the line to include the link in a natural way. Use Markdown format for the link: [text](url).
        The link should be seamlessly integrated into the text.
        Return only the rewritten line without any explanation.
        """

        try:
            response = patched_client.chat.completions.create(
                model="claude-3-haiku-20240307",
                max_tokens=500,
                temperature=0.25,
                messages=[{"role": "user", "content": prompt}],
                response_model=LinkRewrite,
            )
            return response.rewritten_text
        except Exception as e:
            logger.exception("Error generating link insertion", error=e)
            return original_text
</file>

<file path="src/editai/editors/core.py">
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import Dict, List

import diskcache
import instructor
from litellm import completion
from loguru import logger
from pydantic import BaseModel, Field, FilePath

cache = diskcache.Cache("./data/cache/editing")
patched_client = instructor.from_litellm(completion=completion)

DELETE_LINE_MESSAGE = ">>>>>>>>>>>>>>DELETE<<<<<<<<<<<<<<<"


class FixedLine(BaseModel):
    "The fix for a given line of content. It must include the entire line replaced, not just the partial fix."

    replacement_content: str = Field(description="The replacement content for the line")


@dataclass(frozen=True, order=True)
class LineIssue:
    line: int
    issue_message: List[str]


@dataclass(frozen=True, order=True)
class ReplaceLineFixableIssue(LineIssue):
    existing_content: str

    @cache.memoize()
    def fix(self) -> str:
        """
        Fix the line issue using Anthropic's API.

        Returns:
            The corrected line as a string, or the original line if fixing failed.
        """

        try:
            issues_str = "\n".join(self.issue_message)
            logger.info(f"Fixing line issue: {issues_str}")
            # Prepare prompt for Anthropic
            prompt = f"""Rewrite the following line:

<line number={self.line}>
{self.existing_content}
</line>

To fix the following issue:

<issue>
{self.issue_message}
</issue>

Only return the rewritten line. Do not include the line number or any other text.
"""

            # Call Anthropic API
            message = patched_client.chat.completions.create(
                model="anthropic/claude-3-haiku-20240307",
                max_tokens=1000,
                temperature=0.25,  # Be precise
                messages=[{"role": "user", "content": prompt}],
                response_model=FixedLine,
            )

            return message.replacement_content
        except Exception as e:
            logger.error(f"Error fixing line issue: {e}")
            return self.existing_content


@dataclass(frozen=True, order=True)
class InsertLineIssue:
    line: int
    insert_content: str


@dataclass(frozen=True, order=True)
class DeleteLineIssue(ReplaceLineFixableIssue):
    def fix(self) -> str:
        return DELETE_LINE_MESSAGE


class BaseEditor(ABC, BaseModel):
    path: FilePath
    text: str | None = None
    replacements: List[ReplaceLineFixableIssue] = Field(
        default_factory=list, repr=False
    )
    insertions: List[InsertLineIssue] = Field(default_factory=list, repr=False)
    deletions: List[DeleteLineIssue] = Field(default_factory=list, repr=False)

    def get_text(self) -> str:
        if self.text is None:
            with open(self.path, "r") as f:
                self.text = f.read()
        return self.text

    @abstractmethod
    def prerun_checks(self) -> bool:
        pass

    # Add methods for subclasses to add issues
    def add_replacement(self, issue: ReplaceLineFixableIssue):
        self.replacements.append(issue)

    def add_insertion(self, issue: InsertLineIssue):
        self.insertions.append(issue)

    def add_deletion(self, issue: DeleteLineIssue):
        self.deletions.append(issue)

    @abstractmethod
    def collect_issues(self) -> None:
        """Subclasses must implement this method to populate the internal issue lists."""
        pass

    def get_line_number_lookup(self) -> Dict[int, str]:
        return {
            line_number: line_content
            for line_number, line_content in enumerate(self.get_text().split("\n"), 1)
        }

    def get_text_with_line_numbers(self) -> str:
        return "\n".join(
            sorted(
                [
                    f"{line_number}: {line_content}"
                    for line_number, line_content in self.get_line_number_lookup().items()
                ]
            )
        )

    def generate_v2(self) -> str:
        # Ensure text is loaded
        self.get_text()
        # Let subclass populate the issues
        self.collect_issues()

        initial_line_lookup = self.get_line_number_lookup()
        changes: Dict[int, str] = {}  # Store results of fixes/deletions

        # Process replacements
        for issue in self.replacements:
            new_content = issue.fix()
            changes[issue.line] = new_content
            logger.success(f"Replacing line {issue.line} with content: {new_content}")

        # Process deletions
        for issue in self.deletions:
            changes[issue.line] = DELETE_LINE_MESSAGE  # Mark for deletion
            logger.warning(f"Deleting line {issue.line}: {issue.existing_content}")

        final_lines: List[str] = []
        sorted_insertions = sorted(self.insertions, key=lambda x: x.line)
        insertion_idx = 0

        # Iterate through original lines, applying changes and insertions
        for line_no, original_content in sorted(initial_line_lookup.items()):
            # Process insertions BEFORE this line number
            while (
                insertion_idx < len(sorted_insertions)
                and sorted_insertions[insertion_idx].line == line_no
            ):
                insert_issue = sorted_insertions[insertion_idx]
                final_lines.append(insert_issue.insert_content)
                logger.info(
                    f"Inserting before line {line_no}: {insert_issue.insert_content}"
                )
                insertion_idx += 1

            # Process change/deletion for this line number
            if line_no in changes:
                change_content = changes[line_no]
                if change_content != DELETE_LINE_MESSAGE:
                    final_lines.append(change_content)
                # else: line is deleted, do nothing
            else:
                # No change, keep original content
                final_lines.append(original_content)

        # Handle any insertions that should occur after the last line
        while insertion_idx < len(sorted_insertions):
            insert_issue = sorted_insertions[insertion_idx]
            logger.info(
                f"Inserting after last line ({insert_issue.line}): {insert_issue.insert_content}"
            )
            final_lines.append(insert_issue.insert_content)
            insertion_idx += 1

        self.text = "\n".join(final_lines)
        return self.get_text()
</file>

<file path="src/editai/editors/custom_rules.py">
from pathlib import Path
from typing import List, Dict, Optional
import os

from loguru import logger
from pydantic import Field

from .core import BaseEditor, InsertLineIssue, DeleteLineIssue
from .ai import fix_line_edit, LineEdit


class CustomRuleEditor(BaseEditor):
    """
    Editor that applies custom plaintext markdown rules from a directory.
    
    Each rule file contains simple markdown instructions that are processed 
    using the AI editor infrastructure to apply changes to the document.
    """
    
    rules_directory: Path
    include_rules: List[str] = Field(default_factory=list)
    exclude_rules: List[str] = Field(default_factory=list)
    applied_rules: List[str] = Field(default_factory=list)
    dry_run: bool = False
    
    def prerun_checks(self) -> bool:
        """
        Validate that the rules directory exists and contains valid rules.
        """
        if not self.rules_directory.exists():
            logger.error(f"Rules directory does not exist: {self.rules_directory}")
            return False
        
        if not self.rules_directory.is_dir():
            logger.error(f"Rules directory is not a directory: {self.rules_directory}")
            return False
        
        rules = self._load_rules()
        if not rules:
            logger.warning(f"No rules found in directory: {self.rules_directory}")
            return False
        
        logger.success(f"Found {len(rules)} rules in directory: {self.rules_directory}")
        return True
    
    def _load_rules(self) -> Dict[str, str]:
        """
        Load all markdown rule files from the rules directory.
        
        Returns:
            Dict[str, str]: Dictionary of rule name to rule content.
        """
        rules = {}
        
        for file_path in self.rules_directory.glob("*.md"):
            rule_name = file_path.stem
            try:
                with open(file_path, "r") as f:
                    rule_content = f.read()
                rules[rule_name] = rule_content
                logger.info(f"Loaded rule: {rule_name}")
            except Exception as e:
                logger.error(f"Error loading rule {rule_name}: {e}")
        
        return rules
    
    def _filter_rules(self, rules: Dict[str, str]) -> Dict[str, str]:
        """
        Filter rules based on include and exclude lists.
        
        Args:
            rules: Dictionary of rule name to rule content.
            
        Returns:
            Dict[str, str]: Filtered dictionary of rules.
        """
        filtered_rules = {}
        
        # If include_rules is specified, only include those rules
        if self.include_rules:
            for rule_name in self.include_rules:
                if rule_name in rules:
                    filtered_rules[rule_name] = rules[rule_name]
                else:
                    logger.warning(f"Included rule not found: {rule_name}")
        else:
            # Otherwise, include all rules except those in exclude_rules
            filtered_rules = {
                rule_name: rule_content 
                for rule_name, rule_content in rules.items()
                if rule_name not in self.exclude_rules
            }
            
            # Log excluded rules
            for rule_name in self.exclude_rules:
                if rule_name in rules:
                    logger.info(f"Excluding rule: {rule_name}")
                else:
                    logger.warning(f"Excluded rule not found: {rule_name}")
        
        return filtered_rules
    
    def apply_rule(self, rule_content: str, rule_name: str) -> None:
        """
        Apply a single rule to the document using AI.
        
        Args:
            rule_content: The content of the rule file.
            rule_name: The name of the rule.
        """
        text_with_line_numbers = self.get_text_with_line_numbers()
        line_lookup = self.get_line_number_lookup()
        
        # Create a synthetic LineEdit object to use with the existing fix_line_edit function
        # We'll set the starting/ending lines to cover the entire document
        line_edit = LineEdit(
            starting_affected_line=1,
            ending_affected_line=len(line_lookup),
            issue_message=f"Apply rule: {rule_name}",
            resolution="edit"
        )
        
        # Construct prompt for AI
        prompt = f"""You are an expert editor following specific editing instructions.
        
Here is the text with line numbers:
<text>
{text_with_line_numbers}
</text>

Here is the editing instruction to apply:
<rule name="{rule_name}">
{rule_content}
</rule>

Please follow these instructions exactly:
1. Identify lines that need changes based on the rule.
2. Focus only on implementing this specific rule.
3. Return the corrected version of each affected line.
4. If a line doesn't need changes, don't modify it.
5. Preserve the overall structure and line breaks of the document.
"""
        
        # Use the fix_line_edit function to get the corrected text
        corrected_text = fix_line_edit(line_edit, self.get_text())
        
        if corrected_text is None:
            logger.error(f"Failed to apply rule: {rule_name}")
            return
        
        # If we're in dry run mode, just log the changes
        if self.dry_run:
            logger.info(f"Dry run - Rule '{rule_name}' would produce these changes:")
            logger.info(f"Original:\n{self.get_text()}")
            logger.info(f"Modified:\n{corrected_text}")
            return
        
        # Process the corrected text
        original_lines = self.get_text().splitlines()
        corrected_lines = corrected_text.splitlines()
        
        # Detect differences and create replacements/insertions/deletions
        self._process_diff(original_lines, corrected_lines, rule_name)
        
        # Add to applied rules
        self.applied_rules.append(rule_name)
        logger.success(f"Applied rule: {rule_name}")
    
    def _process_diff(self, original_lines: List[str], corrected_lines: List[str], rule_name: str) -> None:
        """
        Process differences between original and corrected lines.
        
        This is a simple implementation that detects basic changes. A more sophisticated
        diff algorithm could be implemented for better results.
        
        Args:
            original_lines: List of original lines.
            corrected_lines: List of corrected lines.
            rule_name: Name of the rule being applied.
        """
        # If line counts are different, handle as complete replacement
        if len(original_lines) != len(corrected_lines):
            logger.info(f"Line count changed from {len(original_lines)} to {len(corrected_lines)}")
            
            # Delete all original lines
            for i, line in enumerate(original_lines, 1):
                self.add_deletion(
                    DeleteLineIssue(
                        line=i,
                        existing_content=line,
                        issue_message=[f"Rule '{rule_name}' replacement"]
                    )
                )
            
            # Insert all new lines
            for i, line in enumerate(corrected_lines, 1):
                self.add_insertion(
                    InsertLineIssue(
                        line=i,
                        insert_content=line
                    )
                )
            return
        
        # Line counts are the same, look for individual line changes
        changes = 0
        for i, (original, corrected) in enumerate(zip(original_lines, corrected_lines), 1):
            if original != corrected:
                # Delete original line
                self.add_deletion(
                    DeleteLineIssue(
                        line=i,
                        existing_content=original,
                        issue_message=[f"Rule '{rule_name}' edit"]
                    )
                )
                
                # Insert corrected line
                self.add_insertion(
                    InsertLineIssue(
                        line=i,
                        insert_content=corrected
                    )
                )
                changes += 1
        
        logger.info(f"Applied {changes} line changes for rule '{rule_name}'")
    
    def collect_issues(self) -> None:
        """
        Load rules, filter them, and apply them to the document.
        """
        # Load all rules
        rules = self._load_rules()
        
        # Filter rules based on include/exclude lists
        filtered_rules = self._filter_rules(rules)
        
        if not filtered_rules:
            logger.warning("No rules to apply after filtering")
            return
        
        logger.info(f"Applying {len(filtered_rules)} rules...")
        
        # Apply rules in alphabetical order
        for rule_name, rule_content in sorted(filtered_rules.items()):
            logger.info(f"Applying rule: {rule_name}")
            self.apply_rule(rule_content, rule_name)
</file>

<file path="src/editai/editors/folder_processor.py">
from pathlib import Path
from typing import Dict, List, Optional, Type, Any, Union
import os

from loguru import logger
from pydantic import BaseModel, Field, FilePath, DirectoryPath

from .core import BaseEditor
from ..utils import find_markdown_files


class FolderProcessor(BaseModel):
    """
    Process multiple markdown files in a directory using a specified editor.
    
    This class acts as a wrapper around the editor classes, applying them to 
    multiple files in a directory rather than a single file.
    """
    
    directory_path: DirectoryPath
    editor_class: Type[BaseEditor]
    editor_kwargs: Dict[str, Any] = Field(default_factory=dict)
    include_pattern: str = "*.md"
    exclude_patterns: List[str] = Field(default_factory=list)
    recursive: bool = True
    
    def process_directory(self, dry_run: bool = False) -> Dict[Path, str]:
        """
        Process all markdown files in the directory using the specified editor.
        
        Args:
            dry_run: If True, don't modify the files, just return what would be changed.
            
        Returns:
            A dictionary mapping file paths to their processed content.
        """
        # Find all markdown files in the directory
        search_pattern = f"**/{self.include_pattern}" if self.recursive else self.include_pattern
        file_paths = list(self.directory_path.glob(search_pattern))
        
        if not file_paths:
            logger.warning(f"No files found matching pattern '{self.include_pattern}' in {self.directory_path}")
            return {}
        
        # Apply exclude patterns if any
        if self.exclude_patterns:
            excluded_files = set()
            for pattern in self.exclude_patterns:
                pattern_with_recursion = f"**/{pattern}" if self.recursive else pattern
                excluded_files.update(self.directory_path.glob(pattern_with_recursion))
            
            file_paths = [f for f in file_paths if f not in excluded_files]
        
        logger.info(f"Found {len(file_paths)} files to process in {self.directory_path}")
        
        # Process each file
        results = {}
        for file_path in file_paths:
            try:
                # Create editor instance for this file
                editor = self.editor_class(path=file_path, **self.editor_kwargs)
                
                # Run prerun checks
                if not editor.prerun_checks():
                    logger.warning(f"Prerun checks failed for {file_path}, skipping")
                    continue
                
                # Process the file
                processed_content = editor.generate_v2()
                results[file_path] = processed_content
                
                # Write the processed content back to the file if not in dry run mode
                if not dry_run:
                    relative_path = file_path.relative_to(self.directory_path)
                    logger.info(f"Writing changes to {relative_path}")
                    with open(file_path, 'w') as f:
                        f.write(processed_content)
                else:
                    logger.info(f"Dry run - would update {file_path.relative_to(self.directory_path)}")
            except Exception as e:
                logger.error(f"Error processing file {file_path}: {e}")
        
        return results
    
    def process_file(self, file_path: Path) -> Optional[str]:
        """
        Process a single file using the specified editor.
        
        Args:
            file_path: The path to the file to process.
            
        Returns:
            The processed content of the file, or None if processing failed.
        """
        try:
            # Create editor instance for this file
            editor = self.editor_class(path=file_path, **self.editor_kwargs)
            
            # Run prerun checks
            if not editor.prerun_checks():
                logger.warning(f"Prerun checks failed for {file_path}, skipping")
                return None
            
            # Process the file
            return editor.generate_v2()
        except Exception as e:
            logger.error(f"Error processing file {file_path}: {e}")
            return None
</file>

<file path="src/editai/editors/images.py">
import base64
import os
import re
import shutil
from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional, Tuple

import diskcache  # type: ignore
import instructor

# litellm imports
import litellm
from litellm import completion
from loguru import logger
from pydantic import BaseModel, Field, FilePath

# Import from .core and potentially other project utils
from .core import (
    BaseEditor,
    DeleteLineIssue,
    InsertLineIssue,
    ReplaceLineFixableIssue,
)

# Constants
cache = diskcache.Cache("./data/cache/image_editor")
patched_client = instructor.from_litellm(completion=completion)


class ImageCaption(BaseModel):
    """Represents the generated caption for an image."""

    caption: str = Field(description="The generated image caption.")


class ImageName(BaseModel):
    """Represents the generated name for an image."""

    name: str = Field(description="The generated image name.")


class InsertLocation(BaseModel):
    """Represents the line number where the image should be inserted."""

    line_number: int = Field(description="The line number for image insertion.")


class ImageAmbles(BaseModel):
    """Represents the preamble and postamble text for an image."""

    preamble: str = Field(description="The preamble text introducing the image.")
    postamble: str = Field(
        description="The postamble text transitioning from the image."
    )


class InternalImage(BaseModel):
    """Represents an image file found for the article."""

    path: Path

    def _get_image_content(self, b64_encode: bool = True) -> str | bytes:
        """Reads image content, optionally base64 encoding it."""
        try:
            with open(self.path, "rb") as f:
                content = f.read()
                if b64_encode:
                    return base64.b64encode(content).decode("utf-8")
                else:
                    return content
        except FileNotFoundError:
            logger.error(f"Image file not found: {self.path}")
            return "" if b64_encode else b""
        except Exception as e:
            logger.error(f"Error reading image {self.path}: {e}")
            return "" if b64_encode else b""

    @cache.memoize()
    def _generate_image_caption(self) -> str:
        """Generates a caption (alt text) for the image using an AI model."""
        image_content = self._get_image_content()
        if not image_content or not isinstance(image_content, str):
            return ""

        try:
            prompt = """Please provide a concise alt text description for this image, suitable for use in an HTML `alt` attribute. Be descriptive but brief.
            """

            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": "image/png",  # Assuming PNG
                                "data": image_content,
                            },
                        },
                        {"type": "text", "text": prompt},
                    ],
                }
            ]

            response: ImageCaption = patched_client(
                model="claude-3-haiku-20240307",
                max_tokens=400,
                messages=messages,
                response_model=ImageCaption,
            )

            logger.success(
                f"Generated image caption for {self.path}: {response.caption}"
            )
            return response.caption

        except Exception as e:
            logger.error(
                f"Error generating image caption for {self.path}: {e}", exc_info=True
            )
            return ""

    @cache.memoize()
    def _generate_image_name(self) -> str:
        """Generates a sanitized file name for the image using an AI model."""
        image_content = self._get_image_content()
        if not image_content or not isinstance(image_content, str):
            return ""

        try:
            prompt = """Please provide a concise, descriptive, lowercase file name for this image, suitable for web use.

            Some tips:
            - Use a short, descriptive name (3-5 words max)
            - Use only lowercase letters and underscores (no spaces or other special characters)
            - Do not include the file extension.
            """

            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": "image/png",  # Assuming PNG
                                "data": image_content,
                            },
                        },
                        {"type": "text", "text": prompt},
                    ],
                }
            ]

            response: ImageName = patched_client(
                model="claude-3-haiku-20240307",
                max_tokens=400,
                messages=messages,
                response_model=ImageName,
            )

            name = response.name.strip().lower().replace(" ", "_")
            # Basic sanitization
            name = re.sub(r"[^\w_]+", "", name)
            # Add extension
            _, ext = os.path.splitext(self.path)
            if not ext:
                ext = ".png"  # Default extension
            final_name = f"{name}{ext}"
            logger.success(f"Generated image name for {self.path}: {final_name}")
            return final_name

        except Exception as e:
            logger.error(
                f"Error generating image name for {self.path}: {e}", exc_info=True
            )
            return ""

    @cache.memoize()
    def get_insert_location(
        self,
        text_with_line_numbers: str,
        blacklist_locations: List[int],
        extra_prompt: str = "",
    ) -> int:
        """Determines the line number where the image should be inserted."""
        image_content = self._get_image_content()
        if not image_content or not isinstance(image_content, str):
            return -1

        prompt = (
            f"""
        You are an expert technical writer assisting in placing an image within an article.
        Analyze the provided text (with line numbers) and the image (shown previously). Determine the single most appropriate line number *after which* to insert this image.

        Here is the text with line numbers:
        <text>
        {text_with_line_numbers}
        </text>

        CRITICAL: Do NOT select any of the following line numbers, as they are already occupied or blacklisted:
        <blacklist_locations>
        {", ".join(map(str, blacklist_locations))}
        </blacklist_locations>

        Consider these factors before deciding:
        - Logical flow: Where does the image best fit to illustrate a concept, introduce a section, or provide context?
        - Relevance: Insert the image near the text it directly relates to.
        - Placement: Generally, images should appear *after* introductory text or a paragraph explaining them, and *before* the detailed content (like code blocks) they illustrate. Avoid placing the image as the very first element.
        - Reader experience: How will placing the image here help the reader understand the content better?

        First, explain your reasoning within <thinking> tags. Then, provide the chosen line number in <line_number> tags.
        """
            + extra_prompt
        )

        try:
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": "image/png",  # Assuming PNG
                                "data": image_content,
                            },
                        },
                        {"type": "text", "text": prompt},
                    ],
                }
            ]

            response: InsertLocation = patched_client(
                model="claude-3-opus-20240229",  # Using Opus for potentially better reasoning
                max_tokens=500,
                messages=messages,
                response_model=InsertLocation,
            )

            line_number = response.line_number
            if line_number in blacklist_locations:
                logger.warning(
                    f"AI chose blacklisted line {line_number} for {self.path}. Retrying.",
                )
                # Simple retry mechanism (could be more robust)
                return self.get_insert_location(
                    text_with_line_numbers,
                    blacklist_locations,
                    " PREVIOUS ATTEMPT FAILED: The line number chosen was blacklisted. Please choose a DIFFERENT line number.",
                )
            logger.success(
                f"Determined insert location for {self.path}: after line {line_number}"
            )
            return line_number

        except Exception as e:
            logger.error(
                f"Error getting insert location for {self.path}: {e}", exc_info=True
            )
            return -1

    @cache.memoize()
    def get_ambles(
        self, text_with_line_numbers: str, caption: str, line_number: int
    ) -> Tuple[str, str]:
        """Generates preamble and postamble text for the image using an AI model."""
        image_content = self._get_image_content()
        if not image_content or not isinstance(image_content, str):
            return "", ""

        try:
            # Rough context extraction (adjust window size as needed)
            context_window = 5
            lines = text_with_line_numbers.splitlines()
            start_line = max(0, line_number - context_window)
            end_line = min(len(lines), line_number + context_window + 1)
            context_text = "\n".join(lines[start_line:end_line])

            prompt = f"""You are an expert technical writer. Given an image (shown previously), its caption ("{caption}"), the line number ({line_number}) where it will be inserted, and the surrounding text context, please write:
            1. A concise preamble (1-2 sentences) to introduce the image. Explain its relevance or what the reader should focus on.
            2. A concise postamble (1 sentence) to transition smoothly from the image to the following text.

            Context (Image will be inserted after line {line_number}):
            <text_context>
            {context_text}
            </text_context>

            Image Caption: {caption}

            Guidelines:
            - Keep ambles brief and natural-sounding.
            - The preamble should precede the image markdown.
            - The postamble should follow the image markdown.
            - If either amble is unnecessary or doesn't make sense, return empty strings.
            """

            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": "image/png",  # Assuming PNG
                                "data": image_content,
                            },
                        },
                        {"type": "text", "text": prompt},
                    ],
                }
            ]

            response: ImageAmbles = patched_client(
                model="claude-3-haiku-20240307",
                max_tokens=500,
                messages=messages,
                response_model=ImageAmbles,
            )

            preamble = response.preamble.strip()
            postamble = response.postamble.strip()

            logger.success(
                f"Generated ambles for {self.path}: Preamble='{preamble}', Postamble='{postamble}'"
            )
            return preamble, postamble

        except Exception as e:
            logger.error(f"Error generating ambles for {self.path}: {e}", exc_info=True)
            return "", ""

    def as_insert_line_issues(
        self,
        text_with_line_numbers: str,
        blacklist_locations: List[int],
        image_url_prefix: str,
    ) -> List[InsertLineIssue]:
        """Generates InsertLineIssue objects for the image and its ambles."""
        insert_issues: List[InsertLineIssue] = []

        # 1. Determine insert location
        # Add current potential insertion points to blacklist temporarily to avoid collisions during generation
        temp_blacklist = list(
            set(blacklist_locations + [i for i in range(1, 5)])
        )  # Include first few lines too
        line_number = self.get_insert_location(text_with_line_numbers, temp_blacklist)
        if line_number == -1:
            logger.warning(
                f"Could not determine insert location for {self.path}. Skipping."
            )
            return []

        # 2. Generate caption and new filename
        caption = self._generate_image_caption()
        if not caption:
            logger.warning(
                f"Could not generate caption for {self.path}. Using filename as fallback."
            )
            caption = os.path.splitext(os.path.basename(self.path))[0].replace(
                "_", " "
            )  # Fallback caption

        new_image_name = self._generate_image_name()
        if not new_image_name:
            logger.error(
                f"Could not generate new name for {self.path}. Cannot create insertion."
            )
            return []  # Cannot insert without a valid name/URL

        # 3. Generate ambles
        preamble, postamble = self.get_ambles(
            text_with_line_numbers, caption, line_number
        )

        # 4. Create InsertLineIssue objects (order matters for application)
        # Insertions happen *after* the specified line number.
        # We want: Preamble -> Image -> Postamble

        insertion_point = (
            line_number  # All insertions happen relative to this original line
        )

        # Add Preamble (if exists) - inserts after line `insertion_point`
        if preamble:
            insert_issues.append(
                InsertLineIssue(line=insertion_point, insert_content=preamble)
            )
            insertion_point += 1  # Next insertion point shifts down

        # Add Image Markdown - inserts after the original line (or preamble if it existed)
        image_markdown = (
            f"![{caption}]({image_url_prefix.rstrip('/')}/{new_image_name})"
        )
        insert_issues.append(
            InsertLineIssue(line=insertion_point, insert_content=image_markdown)
        )
        insertion_point += 1  # Next insertion point shifts down

        # Add Postamble (if exists) - inserts after the image markdown
        if postamble:
            insert_issues.append(
                InsertLineIssue(line=insertion_point, insert_content=postamble)
            )
            # insertion_point += 1 # Not needed for subsequent images in loop

        logger.info(
            f"Prepared {len(insert_issues)} insertions for image {self.path} at line {line_number}"
        )
        return insert_issues


class ImageAdditionEditor(BaseEditor):
    """
    Editor that finds images associated with an article, generates captions and names,
    determines optimal insertion points, and generates markdown insertions with ambles.
    """

    image_url_prefix: str = Field(
        default="/images",
        description="The URL prefix for image paths in the markdown output.",
    )
    image_folder_path: Path = Field(
        description="The path to the subfolder containing images within the article directory.",
    )

    def _get_image_dir(self) -> Optional[str]:
        """Locates the directory containing images for the article."""
        try:
            # Use the potentially imported get_directory function

            image_dir = str(self.image_folder_path)
            if self.image_folder_path.is_dir():
                logger.info(f"Found image directory: {self.image_folder_path}")
                return str(self.image_folder_path)
            else:
                logger.warning(
                    f"Image directory not found at expected location: {self.image_folder_path}"
                )
                return None
        except Exception as e:
            logger.error(f"Error getting images for title '{self.path}': {e}")
            return None

    def _prepare_images(self, image_dir: str) -> List[InternalImage]:
        """Creates InternalImage objects and handles renaming/copying."""
        image_objects: List[InternalImage] = []
        copied_files = (
            set()
        )  # Track successfully copied files to avoid processing originals if copy fails

        try:
            image_files_paths = [
                p
                for p in Path(image_dir).iterdir()
                if p.is_file() and p.suffix.lower() in (".png", ".jpg", ".jpeg", ".gif")
            ]
            image_files = [p.name for p in image_files_paths]
        except FileNotFoundError:
            logger.error(f"Cannot list files, image directory not found: {image_dir}")
            return []
        except Exception as e:
            logger.error(f"Error listing files in image directory {image_dir}: {e}")
            return []

        logger.info(f"Found {len(image_files)} potential image files in {image_dir}")

        for file_path_obj in image_files_paths:
            original_path_str = str(file_path_obj)
            image = InternalImage(path=file_path_obj)
            new_name = image._generate_image_name()

            if new_name:
                new_path_obj = file_path_obj.parent / new_name
                new_path_str = str(new_path_obj)
                if original_path_str.lower() != new_path_str.lower():  # Avoid self-copy
                    try:
                        shutil.copy2(
                            original_path_str, new_path_str
                        )  # shutil usually works fine with str
                        logger.success(
                            f"Copied '{original_path_str}' to '{new_path_str}'"
                        )
                        # Use the new path for the InternalImage object
                        image.path = new_path_obj
                        copied_files.add(
                            new_path_str
                        )  # Add the *new* path string if needed
                        image_objects.append(image)
                    except Exception as e:
                        logger.error(
                            f"Failed to copy '{original_path_str}' to '{new_path_str}': {e}"
                        )
                        # If copy fails, should we still process the original? Maybe not.
                else:
                    # Name generated is the same as original, use original path
                    logger.info(
                        f"Generated name '{new_name}' matches original '{file_path_obj.name}'. Using original."
                    )
                    image_objects.append(image)  # Use original image object
            else:
                logger.warning(
                    f"Could not generate name for '{original_path_str}'. Skipping this image."
                )

        # Log summary
        processed_count = len(image_objects)
        skipped_count = (
            len(image_files) - processed_count
        )  # Approximation if copies failed
        logger.success(
            f"Prepared {processed_count} images for processing. Skipped {skipped_count}."
        )
        return image_objects

    def prerun_checks(self) -> bool:
        """Checks if necessary configurations and directories exist."""
        # Removed anthropic key check
        image_dir = self._get_image_dir()
        if image_dir is None:
            # Logged in _get_image_dir, returning True to allow editor to run (but do nothing)
            return True
        return True

    def collect_issues(self) -> None:
        """Finds images, prepares them, determines locations, and adds insertion issues."""
        image_dir = self._get_image_dir()
        if not image_dir:
            return

        # Prepare images (includes renaming/copying)
        image_objects = self._prepare_images(image_dir)
        if not image_objects:
            logger.info("No images found or prepared. No insertions to generate.")
            return

        text_with_line_numbers = self.get_text_with_line_numbers()  # Use helper method

        # Keep track of lines where insertions *will* happen to avoid conflicts between images
        # Includes line itself and potentially +/- 1 for ambles
        blacklist_locations: List[int] = [0, 1, 2, 3]  # Initial blacklist
        insertions_count = 0

        for image in image_objects:
            # Pass the current blacklist to the image processing method
            current_image_insertions = image.as_insert_line_issues(
                text_with_line_numbers, blacklist_locations, self.image_url_prefix
            )

            if current_image_insertions:
                # Sort insertions for this specific image before adding
                # This ensures ambles and image are added in the correct order relative to each other
                sorted_current_insertions = sorted(
                    current_image_insertions, key=lambda issue: issue.line
                )

                for issue in sorted_current_insertions:
                    self.add_insertion(issue)  # Add to the BaseEditor's list
                    insertions_count += 1

                # Update blacklist with the lines affected by these insertions
                # The insertion line numbers are relative to the *original* document state
                # before these insertions are applied.
                affected_lines = {issue.line for issue in current_image_insertions}
                # Also blacklist lines around the core image insertion for safety
                # Find the core image insertion line (heuristic: middle issue)
                if len(current_image_insertions) > 0:
                    core_line = sorted([i.line for i in current_image_insertions])[
                        len(current_image_insertions) // 2
                    ]
                    affected_lines.add(core_line - 1)
                    affected_lines.add(core_line + 1)

                blacklist_locations.extend(list(affected_lines))
                # Remove duplicates and sort for cleaner logging/debugging
                blacklist_locations = sorted(list(set(blacklist_locations)))

        logger.success(
            f"Collected a total of {insertions_count} line insertions for {len(image_objects)} images."
        )
        # No need to return anything or sort globally here, BaseEditor handles processing order
</file>

<file path="src/editai/editors/links.py">
from typing import List

import diskcache
import instructor
import yaml
from litellm import completion
from loguru import logger
from pydantic import BaseModel, Field, HttpUrl
from smolcrawl.db import Page, TantivyIndexer

from .core import BaseEditor, LineIssue, ReplaceLineFixableIssue
from .utils import get_search_terms

cache = diskcache.Cache("./data/cache/editing")
patched_client = instructor.from_litellm(completion=completion)


class LinkLocation(BaseModel):
    """
    A link location that was found in the text.
    """

    line_number: int = Field(
        description="The line number to link to. This line number MUST refer to text "
    )
    url: HttpUrl = Field(description="The url to link to")
    instructions: str = Field(
        description="Instructions for how to rewrite the line to include the link. This should be a natural way to include the link in the text."
    )


class LinkLocations(BaseModel):
    """
    The reasoning for the list of link locations that were found in the text.

    A list of link locations that were found in the text.
    """

    reasoning: str = Field(description="The reasoning for the list of link locations")
    link_locations: List[LinkLocation] = Field(
        description="A list of link locations that were found in the text, should be lists of line numbers and urls"
    )


def internal_search(search_term: str, index_name: str):
    logger.info(f"Searching for {search_term} in {index_name}")
    db = TantivyIndexer(index_name)
    results = db.query(search_term)
    if not results:
        logger.error(f"No results found for search term {search_term}")
        return []
    return results


def find_link_locations(text: str, search_results: List[Page]) -> List[LinkLocation]:
    search_results_list = []
    for no, result in enumerate(search_results):
        internal_result = {"title": result.title, "url": result.url}
        search_results_list.append(
            f"<result number={no}>\n{yaml.dump(internal_result)}\n</result>"
        )
    search_results_string = "\n".join(search_results_list)
    prompt = f"""You are an expert technical writer.

    You are given a list of search results for a technical blog post or tutorial.
    
    You are also given text with line numbers.

    Your job is to find the best locations in the text to link to the search results.

    <text_with_line_numbers>
    {text}
    </text_with_line_numbers>

    <search_results>
    {search_results_string}
    </search_results>

    Return a list of dictionaries with the following keys:
    - line_number: the line number to link to
    - url: the url to link to

    Rules:
    - The line number MUST refer to text in the <text_with_line_numbers> section.
    - Do not repeat different links for the same location. For each line that you're recommending a link for, only return one link.
    - Only include official looking links.
    - The link should be relevant to the search term, which should in term be relevant to the text.
    - You must only point to lines of text, not code lines or empty lines.
    - NEVER MODIFY CODE LINES.  
    
    Before you return your response, think about the best way to link to the search results. Be sure to use the search term to find a relevant link.
    Only include official looking links.

    Return your response in JSON format with the following structure:
    {{
        "reasoning": "The reasoning for the list of link locations",
        "link_locations": [
            {{
                "line_number": "The line number to link to",
                "url": "The url to link to",
            }}
        ]
    }}
    """
    try:
        response = patched_client.chat.completions.create(
            model="claude-3-haiku-20240307",
            max_tokens=1000,
            temperature=0.25,
            messages=[{"role": "user", "content": prompt}],
            response_model=LinkLocations,
        )
        link_locations = response.link_locations
        logger.success(f"Found {len(link_locations)} link locations")
        return link_locations
    except Exception as e:
        logger.exception("Error finding link locations", error=e)
        return []


def recommend_internal_links(text: str, index_name: str) -> List[LineIssue]:
    search_terms = get_search_terms(text)
    all_search_results = []
    for search_term in search_terms:
        search_results = internal_search(search_term, index_name)
        all_search_results.extend(search_results)

    logger.info(f"Found {len(all_search_results)} search results")

    if not all_search_results:
        return []

    link_locations = find_link_locations(text, all_search_results)

    final_line_issues = []
    for link_location in link_locations:
        final_line_issues.append(
            LineIssue(
                line=link_location.line_number,
                issue_message=[
                    f"{link_location.instructions}. Rewrite this line to include, in a natural way, an inline link to {link_location.url}. Make the link in markdown format."
                ],
            )
        )
    return final_line_issues


class InternalLinkEditor(BaseEditor):
    indexes: List[str]

    def prerun_checks(self) -> bool:
        for index_name in self.indexes:
            index = TantivyIndexer(index_name, create_if_missing=False)
            if not index.exists():
                logger.error(f"Index {index_name} does not exist")
                return False

        return True

    def collect_issues(self) -> None:
        """Recommends internal links based on search terms and adds them as replacement issues."""
        text_with_line_numbers = self.get_text_with_line_numbers()
        line_lookup = self.get_line_number_lookup()
        replacements_count = 0

        for index_name in self.indexes:
            logger.info(f"Processing index: {index_name}")
            recd_links = recommend_internal_links(text_with_line_numbers, index_name)

            if not recd_links:
                logger.info(f"No internal links found for index {index_name}")
                continue

            logger.success(
                f"Found {len(recd_links)} potential internal link locations for index {index_name}"
            )

            for link_issue in recd_links:
                # Ensure the line exists in the current text
                if link_issue.line in line_lookup:
                    replacement_issue = ReplaceLineFixableIssue(
                        line=link_issue.line,
                        issue_message=link_issue.issue_message,
                        existing_content=line_lookup[link_issue.line],
                    )
                    self.add_replacement(replacement_issue)
                    replacements_count += 1
                else:
                    logger.warning(
                        f"Skipping recommended link for line {link_issue.line} as it does not exist in the lookup."
                    )

        logger.success(
            f"Collected {replacements_count} line replacement issues for internal links."
        )
</file>

<file path="src/editai/editors/utils.py">
import re
from typing import List

import instructor
from litellm import completion
from loguru import logger
from pydantic import BaseModel, Field

patched_client = instructor.from_litellm(completion=completion)


class SearchTerms(BaseModel):
    search_terms: List[str] = Field(
        description="A list of up to 12 search terms wrapped in <search_terms> tags and separated by commas."
    )


def get_search_terms(text: str) -> List[str]:
    logger.info("Getting search terms for text", text=text)
    prompt = f"""
    Extract up to 12 key search terms from the following text. Return a list of up to 12 search terms wrapped in <search_terms> tags and separated by commas.

    <text>
    {text}
    </text>

    Return a list of up to 5 search terms wrapped in <search_terms> tags and separated by commas.

    <example>
    This is a technical blog post or tutorial, so focus on the more technical tools, concepts, and terms that we should link to and search for.

    For instance, if the code includes 
    ```python
    from mcp.server.fastmcp import FastMCP
    ````

    Then good search terms would be "FastMCP" and "MCP Server". 
    </example>
    
    Rules:
    - Focus in particular on the names from the imported lobraries and their names.
    - Don't include concepts that aren't related to the technical content of the text. For instance, if the demo is about whales, don't include "whales" in the search terms.
    - Focus on the terms related to the libraries used. For instances, the imported classes, functions names, etc.
    - Do not use search terms that seem specific to the demo, but rather focus on the libraries used.

    First use a <thinking> block to think about the best search terms. Then return your response wrapped in <search_terms> tags.
    """
    response = patched_client.messages.create(
        model="anthropic/claude-3-haiku-20240307",
        max_tokens=800,
        temperature=0.25,
        messages=[{"role": "user", "content": prompt}],
        response_model=SearchTerms,
    )
    return response.search_terms
</file>

<file path="src/editai/editors/vale.py">
import json
import os
import subprocess
import tempfile
from dataclasses import dataclass, field
from typing import List, Optional

from loguru import logger
from pydantic import FilePath

from .core import (
    BaseEditor,
    DeleteLineIssue,
    InsertLineIssue,
    LineIssue,
    ReplaceLineFixableIssue,
)


@dataclass
class ActionC:
    Name: str = ""
    Params: Optional[List[str]] = None


@dataclass
class ValeAlert:
    Action: ActionC = field(default_factory=ActionC)
    Span: List[int] = field(default_factory=list)
    Check: str = ""
    Description: str = ""
    Link: str = ""
    Message: str = ""
    Severity: str = ""
    Match: str = ""
    Line: int = 0

    def as_line_issue(self) -> LineIssue:
        return LineIssue(
            line=self.Line,
            issue_message=[self.Check + " - " + self.Message],
        )


@dataclass
class ValeFileReport:
    issues: List[ValeAlert] = field(default_factory=list)

    def as_line_issues(self) -> List[LineIssue]:
        return [alert.as_line_issue() for alert in self.issues]


def check_vale_installation() -> bool:
    try:
        # Run 'vale --version' and capture the output
        result = subprocess.run(
            ["vale", "--version"],
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
        )
        # If the command runs successfully, Vale is installed
        return True
    except FileNotFoundError:
        # If 'vale' command is not found, Vale is not installed or not in PATH
        return False
    except subprocess.CalledProcessError as e:
        # Handle other potential errors during the command execution
        logger.error(f"Error checking Vale installation: {e}")
        return False


def run_vale(text: str, vale_config_path: str) -> List[LineIssue]:
    if not check_vale_installation():
        logger.error("Vale is not installed or not found in PATH")
        return []

    vale_dir = os.environ.get("PROJECT_ROOT", os.getcwd())

    # Create a temporary file and ensure it's written and closed
    with tempfile.NamedTemporaryFile(
        dir=vale_dir, mode="w", suffix=".md", delete=False
    ) as temp_file:
        temp_file.write(text)
        temp_file_path = temp_file.name

    try:
        # Get the full path to vale
        vale_path = subprocess.check_output(["which", "vale"]).decode().strip()

        # Run vale with the correct working directory and environment
        result = subprocess.run(
            [vale_path, "--config", vale_config_path, "--output=JSON", temp_file_path],
            capture_output=True,
            text=True,
            cwd=vale_dir,
            env=dict(os.environ, PATH=os.environ.get("PATH", "")),
        )

        logger.success("Vale Result", result=result)
        # Parse the JSON output
        as_json = json.loads(result.stdout)
        logger.success("Vale JSON", json=as_json)

        # Convert JSON alerts into ValeAlert objects
        issues = []
        for file_path, alerts in as_json.items():
            logger.info(f"Found {len(alerts)} alerts in {file_path}")
            for alert in alerts:
                action = ActionC(
                    Name=alert.get("Action", {}).get("Name", ""),
                    Params=alert.get("Action", {}).get("Params"),
                )
                issues.append(
                    ValeAlert(
                        Action=action,
                        Span=alert.get("Span", []),
                        Check=alert.get("Check", ""),
                        Description=alert.get("Description", ""),
                        Link=alert.get("Link", ""),
                        Message=alert.get("Message", ""),
                        Severity=alert.get("Severity", ""),
                        Match=alert.get("Match", ""),
                        Line=alert.get("Line", 0),
                    )
                )

        report = ValeFileReport(issues=issues)
        logger.success("Vale Report", report=report)
        return report.as_line_issues()

    except Exception as e:
        logger.exception("Error running Vale", error=e)
        return []
    finally:
        # Clean up the temporary file
        try:
            os.remove(temp_file_path)
        except Exception as e:
            logger.exception("Error removing temporary file", error=e)


class ValeEditor(BaseEditor):
    vale_config_path: FilePath

    def prerun_checks(self) -> bool:
        vale_installed = check_vale_installation()
        vale_config_exists = os.path.exists(str(self.vale_config_path))
        return vale_installed and vale_config_exists

    def collect_issues(self) -> None:
        """Runs Vale and adds any reported issues as replacement issues."""
        issues = run_vale(self.get_text(), str(self.vale_config_path))
        if not issues:
            logger.info("Vale reported no issues.")
            return

        line_lookup = self.get_line_number_lookup()
        replacements_count = 0

        for issue in issues:
            # Ensure the line number from Vale is valid
            if issue.line in line_lookup:
                replacement_issue = ReplaceLineFixableIssue(
                    line=issue.line,
                    issue_message=issue.issue_message,
                    existing_content=line_lookup[issue.line],
                )
                self.add_replacement(replacement_issue)
                replacements_count += 1
            else:
                logger.warning(
                    f"Skipping Vale issue for line {issue.line} as it's not in the lookup (maybe out of bounds?). Message: {issue.issue_message}"
                )

        logger.success(
            f"Collected {replacements_count} line replacement issues from Vale."
        )
</file>

<file path="src/editai/__init__.py">
from dotenv import load_dotenv

load_dotenv()
</file>

<file path="src/editai/cli.py">
from pathlib import Path
import os
from typing import List, Optional, Union

import typer
from loguru import logger
from pydantic import DirectoryPath
from smolcrawl import list_indices as list_indices_from_smolcrawl

from .editors.ai import AIEditor
from .editors.arbitrary_links import ArbitraryLinkEditor
from .editors.custom_rules import CustomRuleEditor
from .editors.folder_processor import FolderProcessor
from .editors.images import ImageAdditionEditor
from .editors.links import InternalLinkEditor
from .editors.vale import ValeEditor
from .utils import get_vale_config_path

app = typer.Typer()


def is_directory(path: str) -> bool:
    """Check if a path is a directory."""
    return os.path.isdir(path)


@app.command()
def vale(
    path: str,
    vale_config_path: str | None = None,
    recursive: bool = False,
    include_pattern: str = "*.md",
    exclude_patterns: List[str] = None,
    dry_run: bool = False
):
    """
    Run Vale on file(s) to identify style issues.

    If path is a directory, process all markdown files in the directory.
    Otherwise, process the single file at path.
    """
    path_obj = Path(path)

    # Determine Vale config path
    vale_config_path_final: Path
    if vale_config_path is None:
        maybe_path = get_vale_config_path()
        if maybe_path is None:
            print("Error: Vale config path could not be determined.")
            raise typer.Exit(code=1)
        vale_config_path_final = maybe_path
    else:
        vale_config_path_final = Path(vale_config_path)

    if is_directory(path):
        # Process directory
        processor = FolderProcessor(
            directory_path=path_obj,
            editor_class=ValeEditor,
            editor_kwargs={"vale_config_path": vale_config_path_final},
            include_pattern=include_pattern,
            exclude_patterns=exclude_patterns or [],
            recursive=recursive
        )
        results = processor.process_directory(dry_run=dry_run)

        # Print summary
        if not dry_run:
            print(f"Processed {len(results)} files with Vale.")
        else:
            print(f"Dry run - would process {len(results)} files with Vale.")
    else:
        # Process single file
        editor = ValeEditor(path=path_obj, vale_config_path=vale_config_path_final)
        processed_content = editor.generate_v2()

        if not dry_run:
            with open(path_obj, 'w') as f:
                f.write(processed_content)
            print(f"Processed file: {path_obj}")
        else:
            print(f"Dry run - would update {path_obj}")
            print(processed_content)


@app.command()
def list_indices():
    list_indices_from_smolcrawl()


@app.command()
def links(
    path: str,
    local_index_names: List[str] = [],
    websearch: bool = False,
    recursive: bool = False,
    include_pattern: str = "*.md",
    exclude_patterns: List[str] = None,
    dry_run: bool = False
):
    """
    Add internal links to document(s).

    If path is a directory, process all markdown files in the directory.
    Otherwise, process the single file at path.
    """
    path_obj = Path(path)

    # Parse comma-separated list of indexes
    if len(local_index_names) == 1 and "," in local_index_names[0]:
        local_index_names = local_index_names[0].split(",")

    if is_directory(path):
        # Process directory
        processor = FolderProcessor(
            directory_path=path_obj,
            editor_class=InternalLinkEditor,
            editor_kwargs={"indexes": local_index_names},
            include_pattern=include_pattern,
            exclude_patterns=exclude_patterns or [],
            recursive=recursive
        )
        results = processor.process_directory(dry_run=dry_run)

        # Print summary
        if not dry_run:
            print(f"Processed {len(results)} files with internal links.")
        else:
            print(f"Dry run - would process {len(results)} files with internal links.")
    else:
        # Process single file
        editor = InternalLinkEditor(path=path_obj, indexes=local_index_names)
        processed_content = editor.generate_v2()

        if not dry_run:
            with open(path_obj, 'w') as f:
                f.write(processed_content)
            print(f"Processed file: {path_obj}")
        else:
            print(f"Dry run - would update {path_obj}")
            print(processed_content)


@app.command()
def add_images(
    path: str,
    image_folder_path: str,
    image_url_prefix: str = "/images",
    recursive: bool = False,
    include_pattern: str = "*.md",
    exclude_patterns: List[str] = None,
    dry_run: bool = False
):
    """
    Add images to document(s).

    If path is a directory, process all markdown files in the directory.
    Otherwise, process the single file at path.
    """
    path_obj = Path(path)
    image_folder_path_obj = Path(image_folder_path)

    if is_directory(path):
        # Process directory
        processor = FolderProcessor(
            directory_path=path_obj,
            editor_class=ImageAdditionEditor,
            editor_kwargs={
                "image_folder_path": image_folder_path_obj,
                "image_url_prefix": image_url_prefix
            },
            include_pattern=include_pattern,
            exclude_patterns=exclude_patterns or [],
            recursive=recursive
        )
        results = processor.process_directory(dry_run=dry_run)

        # Print summary
        if not dry_run:
            print(f"Processed {len(results)} files with image additions.")
        else:
            print(f"Dry run - would process {len(results)} files with image additions.")
    else:
        # Process single file
        editor = ImageAdditionEditor(
            path=path_obj,
            image_folder_path=image_folder_path_obj,
            image_url_prefix=image_url_prefix,
        )
        processed_content = editor.generate_v2()

        if not dry_run:
            with open(path_obj, 'w') as f:
                f.write(processed_content)
            print(f"Processed file: {path_obj}")
        else:
            print(f"Dry run - would update {path_obj}")
            print(processed_content)


@app.command()
def ai(
    path: str,
    recursive: bool = False,
    include_pattern: str = "*.md",
    exclude_patterns: List[str] = None,
    dry_run: bool = False
):
    """
    Use AI to improve document(s).

    If path is a directory, process all markdown files in the directory.
    Otherwise, process the single file at path.
    """
    path_obj = Path(path)

    if is_directory(path):
        # Process directory
        processor = FolderProcessor(
            directory_path=path_obj,
            editor_class=AIEditor,
            editor_kwargs={},
            include_pattern=include_pattern,
            exclude_patterns=exclude_patterns or [],
            recursive=recursive
        )
        results = processor.process_directory(dry_run=dry_run)

        # Print summary
        if not dry_run:
            print(f"Processed {len(results)} files with AI editor.")
        else:
            print(f"Dry run - would process {len(results)} files with AI editor.")
    else:
        # Process single file
        editor = AIEditor(path=path_obj)
        processed_content = editor.generate_v2()

        if not dry_run:
            with open(path_obj, 'w') as f:
                f.write(processed_content)
            print(f"Processed file: {path_obj}")
        else:
            print(f"Dry run - would update {path_obj}")
            print(processed_content)


@app.command()
def arbitrary_links(path: str):
    """
    Interactive REPL to add arbitrary links to a document.
    Prompts for URLs and descriptions, then finds the best placement for each link.

    Note: This command doesn't support directory processing since it's interactive.
    """
    path_obj = Path(path)

    if is_directory(path):
        print("Error: arbitrary_links command doesn't support directory processing.")
        print("Please specify a single file path instead.")
        raise typer.Exit(code=1)

    editor = ArbitraryLinkEditor(path=path_obj)
    print(editor.generate_v2())


@app.command()
def custom_rules(
    path: str,
    rules_directory: str,
    include_rules: Optional[List[str]] = None,
    exclude_rules: Optional[List[str]] = None,
    recursive: bool = False,
    include_pattern: str = "*.md",
    exclude_patterns: List[str] = None,
    dry_run: bool = False
):
    """
    Apply custom plaintext markdown rules to document(s).

    If path is a directory, process all markdown files in the directory.
    Otherwise, process the single file at path.
    """
    path_obj = Path(path)
    rules_dir_obj = Path(rules_directory)

    # Handle include_rules and exclude_rules list parsing
    include_list = []
    exclude_list = []

    if include_rules:
        if len(include_rules) == 1 and "," in include_rules[0]:
            include_list = include_rules[0].split(",")
        else:
            include_list = include_rules

    if exclude_rules:
        if len(exclude_rules) == 1 and "," in exclude_rules[0]:
            exclude_list = exclude_rules[0].split(",")
        else:
            exclude_list = exclude_rules

    if is_directory(path):
        # Process directory
        processor = FolderProcessor(
            directory_path=path_obj,
            editor_class=CustomRuleEditor,
            editor_kwargs={
                "rules_directory": rules_dir_obj,
                "include_rules": include_list,
                "exclude_rules": exclude_list,
                "dry_run": dry_run
            },
            include_pattern=include_pattern,
            exclude_patterns=exclude_patterns or [],
            recursive=recursive
        )
        results = processor.process_directory(dry_run=dry_run)

        # Print summary
        if not dry_run:
            print(f"Processed {len(results)} files with custom rules.")
        else:
            print(f"Dry run - would process {len(results)} files with custom rules.")
    else:
        # Process single file
        editor = CustomRuleEditor(
            path=path_obj,
            rules_directory=rules_dir_obj,
            include_rules=include_list,
            exclude_rules=exclude_list,
            dry_run=dry_run
        )

        processed_content = editor.generate_v2()

        if not dry_run:
            with open(path_obj, 'w') as f:
                f.write(processed_content)
            print(f"Processed file: {path_obj}")
        else:
            print(f"Dry run - would update {path_obj}")
            print(processed_content)


@app.command()
def list_rules(rules_directory: str):
    """List all available rules in the directory."""
    rules_dir_obj = Path(rules_directory)

    if not rules_dir_obj.exists() or not rules_dir_obj.is_dir():
        print(f"Error: Rules directory does not exist or is not a directory: {rules_directory}")
        raise typer.Exit(code=1)

    rules = list(rules_dir_obj.glob("*.md"))

    if not rules:
        print(f"No rules found in directory: {rules_directory}")
        return

    print(f"Found {len(rules)} rules in directory: {rules_directory}\n")
    for rule_path in sorted(rules):
        print(f"- {rule_path.stem}")


@app.command()
def view_rule(rules_directory: str, rule_name: str):
    """Display the content of a specific rule."""
    rules_dir_obj = Path(rules_directory)

    if not rule_name.endswith(".md"):
        rule_name = f"{rule_name}.md"

    rule_path = rules_dir_obj / rule_name

    if not rule_path.exists():
        print(f"Error: Rule not found: {rule_name}")
        raise typer.Exit(code=1)

    try:
        with open(rule_path, "r") as f:
            rule_content = f.read()
        print(f"--- Rule: {rule_path.stem} ---\n")
        print(rule_content)
    except Exception as e:
        print(f"Error reading rule: {e}")
        raise typer.Exit(code=1)


@app.command()
def create_rule(rules_directory: str, rule_name: str):
    """Create a new empty rule file."""
    rules_dir_obj = Path(rules_directory)

    if not rules_dir_obj.exists():
        print(f"Creating rules directory: {rules_directory}")
        rules_dir_obj.mkdir(parents=True)

    if not rule_name.endswith(".md"):
        rule_name = f"{rule_name}.md"

    rule_path = rules_dir_obj / rule_name

    if rule_path.exists():
        print(f"Error: Rule already exists: {rule_name}")
        raise typer.Exit(code=1)

    try:
        with open(rule_path, "w") as f:
            f.write(f"""# Rule: {rule_path.stem}

Instructions for the rule go here. Describe the changes to make to the document.

Example:
- Find instances of passive voice and convert to active voice
- Ensure bullet points are consistently formatted
- Replace deprecated terminology with approved terms
""")
        print(f"Created rule: {rule_path}")
    except Exception as e:
        print(f"Error creating rule: {e}")
        raise typer.Exit(code=1)


if __name__ == "__main__":
    app()
</file>

<file path="src/editai/py.typed">

</file>

<file path="src/editai/utils.py">
import os
import re
from collections import Counter
from pathlib import Path
from typing import Dict, List, Optional, Union, Callable, Set

import spacy


def get_word_counts(text: str) -> list[tuple[str, int]]:
    words = text.lower().split()
    return Counter(words).most_common(20)


def remove_code_blocks(text: str) -> str:
    """Removes code blocks from a string.

    Args:
        text: The input string.

    Returns:
        The string with code blocks removed.
    """
    return re.sub(r"```.*?```", "", text, flags=re.DOTALL)


def remove_inline_code(text: str) -> str:
    """Removes inline code snippets from a string.

    Args:
        text: The input string.

    Returns:
        The string with inline code removed.
    """
    return re.sub(r"`[^`]*`", "", text)


def get_sentences(text: str) -> list[str]:
    """
    Returns a list of sentences from the given text.
    """
    nlp = spacy.load("en_core_web_sm")
    doc = nlp(text)
    return [sentence.text for sentence in doc.sents]


def calculate_sentence_lengths(text: str) -> list[int]:
    """
    Calculates the length of each sentence in the given text.

    Args:
        text: The input text.

    Returns:
        A list of sentence lengths.
    """
    nlp = spacy.load("en_core_web_sm")
    doc = nlp(text)
    return [len(sentence) for sentence in doc.sents]


def get_sentence_length_stats(text: str) -> dict[str, float]:
    """
    Calculates the min, max, average, and median sentence length of the given text.

    Args:
        text: The input text.

    Returns:
        A dictionary containing the min, max, average, and median sentence lengths.
    """
    text = remove_code_blocks(text)
    text = remove_inline_code(text)
    sentence_lengths = calculate_sentence_lengths(text)
    if not sentence_lengths:
        return {
            "min": 0.0,
            "max": 0.0,
            "average": 0.0,
            "median": 0.0,
        }
    min_length = min(sentence_lengths)
    max_length = max(sentence_lengths)
    average_length = sum(sentence_lengths) / len(sentence_lengths)
    sorted_lengths = sorted(sentence_lengths)
    median_length = (
        sorted_lengths[len(sorted_lengths) // 2]
        if len(sorted_lengths) % 2 != 0
        else (
            sorted_lengths[len(sorted_lengths) // 2 - 1]
            + sorted_lengths[len(sorted_lengths) // 2]
        )
        / 2
    )
    return {
        "min": float(min_length),
        "max": float(max_length),
        "average": average_length,
        "median": median_length,
    }


def count_words(
    text: str,
    exclude_stopwords: bool = True,
    exclude_punctuation: bool = True,
    exclude_digits: bool = False,
    min_word_length: int = 1,
    language_model: str = "en_core_web_sm",
) -> Dict[str, int]:
    """
    Count words in text, with options to filter out stopwords and other elements.

    Args:
        text: The input text to analyze
        exclude_stopwords: Whether to exclude common stopwords
        exclude_punctuation: Whether to exclude punctuation
        exclude_digits: Whether to exclude words containing digits
        min_word_length: Minimum word length to include in counts
        language_model: spaCy language model to use

    Returns:
        Dictionary with words as keys and their counts as values
    """
    # Remove code blocks
    text = re.sub(r"```.*?```", "", text, flags=re.DOTALL)
    # Remove newlines and backticks
    text = text.replace("\n", "").replace("`", "")

    # Load spaCy model
    nlp = spacy.load(language_model)

    # Process the text
    doc = nlp(text)

    # Filter words based on parameters
    filtered_words = []
    for token in doc:
        # Convert to lowercase
        word = token.text.lower()

        # Apply filters
        if exclude_stopwords and token.is_stop:
            continue
        if exclude_punctuation and token.is_punct:
            continue
        if exclude_digits and token.like_num:
            continue
        if len(word) < min_word_length:
            continue

        filtered_words.append(word)

    # Count word frequencies
    return dict(Counter(filtered_words).most_common(20))


def count_adjectives(
    text: str,
    exclude_stopwords: bool = True,
    exclude_punctuation: bool = True,
    exclude_digits: bool = False,
    min_word_length: int = 1,
    language_model: str = "en_core_web_sm",
) -> Dict[str, int]:
    """
    Count adjectives in text, with options to filter out stopwords and other elements.

    Args:
        text: The input text to analyze
        exclude_stopwords: Whether to exclude common stopwords
        exclude_punctuation: Whether to exclude punctuation
        exclude_digits: Whether to exclude words containing digits
        min_word_length: Minimum word length to include in counts
        language_model: spaCy language model to use

    Returns:
        Dictionary with adjectives as keys and their counts as values
    """
    text = remove_code_blocks(text)
    text = remove_inline_code(text)

    # Load spaCy model
    nlp = spacy.load(language_model)

    # Process the text
    doc = nlp(text)

    # Filter adjectives based on parameters
    filtered_adjectives = []
    for token in doc:
        # Apply filters

        if token.pos_ != "ADJ":
            continue

        word = token.text.lower()

        if exclude_stopwords and token.is_stop:
            continue
        if exclude_punctuation and token.is_punct:
            continue
        if exclude_digits and token.like_num:
            continue
        if len(word) < min_word_length:
            continue

        filtered_adjectives.append(word)

    # Count adjective frequencies
    return dict(Counter(filtered_adjectives).most_common(20))


def get_vale_config_path() -> str | None:
    return os.getenv("VALE_CONFIG_PATH")


def find_markdown_files(
    directory_path: Path, 
    include_pattern: str = "*.md", 
    exclude_patterns: List[str] = None
) -> List[Path]:
    """
    Find markdown files in a directory (and its subdirectories) that match the include pattern
    and don't match any of the exclude patterns.

    Args:
        directory_path: The path to the directory to search in.
        include_pattern: Glob pattern for files to include (default is "*.md").
        exclude_patterns: List of glob patterns for files to exclude.

    Returns:
        A list of file paths matching the criteria.
    """
    exclude_patterns = exclude_patterns or []
    
    # Ensure the directory exists
    if not directory_path.exists() or not directory_path.is_dir():
        raise ValueError(f"Directory does not exist or is not a directory: {directory_path}")
    
    # Find all files matching the include pattern
    all_files = list(directory_path.glob(f"**/{include_pattern}"))
    
    # Apply exclude patterns
    if exclude_patterns:
        excluded_files: Set[Path] = set()
        for pattern in exclude_patterns:
            excluded_files.update(directory_path.glob(f"**/{pattern}"))
        
        # Filter out excluded files
        return [f for f in all_files if f not in excluded_files]
    
    return all_files


def process_files_in_directory(
    directory_path: Path, 
    processor_func: Callable[[Path], str], 
    include_pattern: str = "*.md",
    exclude_patterns: List[str] = None,
    dry_run: bool = False
) -> Dict[Path, str]:
    """
    Process all matching files in a directory using the provided processor function.
    
    Args:
        directory_path: The path to the directory containing files to process.
        processor_func: A function that takes a file path and returns the processed content.
        include_pattern: Glob pattern for files to include (default is "*.md").
        exclude_patterns: List of glob patterns for files to exclude.
        dry_run: If True, files won't be modified, only return the processed content.
        
    Returns:
        A dictionary mapping file paths to their processed content.
    """
    files = find_markdown_files(directory_path, include_pattern, exclude_patterns)
    
    # Process each file
    results = {}
    for file_path in files:
        try:
            # Process the file
            processed_content = processor_func(file_path)
            results[file_path] = processed_content
            
            # Write the processed content back to the file if not in dry run mode
            if not dry_run and processed_content:
                with open(file_path, 'w') as f:
                    f.write(processed_content)
        except Exception as e:
            # Log the error and continue with the next file
            from loguru import logger
            logger.error(f"Error processing file {file_path}: {e}")
    
    return results
</file>

<file path="test_rules/bullet_consistency.md">
# Ensure Bullet Point Consistency

Ensure all bullet point lists use consistent capitalization and punctuation.

Each list item should:
1. Start with a capital letter
2. End with a period if it's a complete sentence
3. Not have a period if it's a phrase or incomplete sentence
4. Maintain parallel structure (all items should be the same grammatical form)

Apply this rule to all bullet point lists in the document.
</file>

<file path="test_rules/new_test_rule.md">
# Rule: new_test_rule

Instructions for the rule go here. Describe the changes to make to the document.

Example:
- Find instances of passive voice and convert to active voice
- Ensure bullet points are consistently formatted
- Replace deprecated terminology with approved terms
</file>

<file path="test_rules/passive_voice.md">
# Convert Passive Voice to Active Voice

Find instances of passive voice in the document and convert them to active voice. 
Focus particularly on phrases like "is being done", "was performed", "has been completed", etc.
Convert them to their active equivalents.

For example:
- "The test is being performed" → "We are performing the test"
- "The data was analyzed" → "We analyzed the data"
- "The code has been reviewed" → "The team reviewed the code"

Only change sentences that would be clearer in active voice.
</file>

<file path="tests/test_folder_processor.py">
import os
import tempfile
from pathlib import Path
from unittest import TestCase, mock

from editai.editors.folder_processor import FolderProcessor
from editai.editors.core import BaseEditor


class MockEditor(BaseEditor):
    """Mock editor for testing the folder processor."""
    
    def prerun_checks(self) -> bool:
        return True
    
    def collect_issues(self) -> None:
        # Mock implementation - just append a marker to the content
        pass
    
    def generate_v2(self) -> str:
        # Mock implementation - just append a marker to the content
        content = self.get_text()
        return f"{content}\n<!-- Processed by MockEditor -->"


class TestFolderProcessor(TestCase):
    """Tests for the FolderProcessor class."""
    
    def setUp(self):
        """Set up a temporary directory with test files."""
        self.temp_dir = tempfile.TemporaryDirectory()
        self.test_dir = Path(self.temp_dir.name)
        
        # Create test files
        self.md_files = []
        for i in range(3):
            file_path = self.test_dir / f"test{i}.md"
            with open(file_path, "w") as f:
                f.write(f"# Test Document {i}\n\nThis is test document {i}.")
            self.md_files.append(file_path)
        
        # Create a non-markdown file
        self.txt_file = self.test_dir / "test.txt"
        with open(self.txt_file, "w") as f:
            f.write("This is not a markdown file.")
        
        # Create a subdirectory with more files
        self.subdir = self.test_dir / "subdir"
        self.subdir.mkdir()
        self.subdir_files = []
        for i in range(2):
            file_path = self.subdir / f"subtest{i}.md"
            with open(file_path, "w") as f:
                f.write(f"# Subdir Test Document {i}\n\nThis is subdir test document {i}.")
            self.subdir_files.append(file_path)
    
    def tearDown(self):
        """Clean up temporary directory."""
        self.temp_dir.cleanup()
    
    def test_process_directory_non_recursive(self):
        """Test processing a directory without recursion."""
        processor = FolderProcessor(
            directory_path=self.test_dir,
            editor_class=MockEditor,
            recursive=False
        )
        
        results = processor.process_directory(dry_run=True)
        
        # Should find only the markdown files in the top directory
        self.assertEqual(len(results), 3)
        for file_path in self.md_files:
            self.assertIn(file_path, results)
            self.assertIn("<!-- Processed by MockEditor -->", results[file_path])
        
        # Should not include subdirectory files
        for file_path in self.subdir_files:
            self.assertNotIn(file_path, results)
    
    def test_process_directory_recursive(self):
        """Test processing a directory with recursion."""
        processor = FolderProcessor(
            directory_path=self.test_dir,
            editor_class=MockEditor,
            recursive=True
        )
        
        results = processor.process_directory(dry_run=True)
        
        # Should find all markdown files, including those in subdirectories
        self.assertEqual(len(results), 5)
        for file_path in self.md_files + self.subdir_files:
            self.assertIn(file_path, results)
            self.assertIn("<!-- Processed by MockEditor -->", results[file_path])
    
    def test_include_pattern(self):
        """Test using an include pattern to filter files."""
        processor = FolderProcessor(
            directory_path=self.test_dir,
            editor_class=MockEditor,
            include_pattern="test1*.md",  # Only include files starting with test1
            recursive=True
        )
        
        results = processor.process_directory(dry_run=True)
        
        # Should only find test1.md
        self.assertEqual(len(results), 1)
        self.assertIn(self.test_dir / "test1.md", results)
    
    def test_exclude_patterns(self):
        """Test using exclude patterns to filter files."""
        processor = FolderProcessor(
            directory_path=self.test_dir,
            editor_class=MockEditor,
            exclude_patterns=["*1.md", "subdir/*"],  # Exclude all files with 1 in name and all in subdir
            recursive=True
        )
        
        results = processor.process_directory(dry_run=True)
        
        # Should find test0.md and test2.md, but not test1.md or any in subdir
        self.assertEqual(len(results), 2)
        self.assertIn(self.test_dir / "test0.md", results)
        self.assertIn(self.test_dir / "test2.md", results)
        self.assertNotIn(self.test_dir / "test1.md", results)
        for file_path in self.subdir_files:
            self.assertNotIn(file_path, results)
    
    def test_dry_run_mode(self):
        """Test that dry run mode doesn't modify files."""
        # Read the original content
        original_contents = {}
        for file_path in self.md_files:
            with open(file_path, "r") as f:
                original_contents[file_path] = f.read()
        
        processor = FolderProcessor(
            directory_path=self.test_dir,
            editor_class=MockEditor,
            recursive=False
        )
        
        # Process in dry run mode
        processor.process_directory(dry_run=True)
        
        # Check that files are unchanged
        for file_path in self.md_files:
            with open(file_path, "r") as f:
                current_content = f.read()
            self.assertEqual(current_content, original_contents[file_path])
    
    def test_actual_modification(self):
        """Test that files are actually modified when not in dry run mode."""
        processor = FolderProcessor(
            directory_path=self.test_dir,
            editor_class=MockEditor,
            recursive=False
        )
        
        # Process without dry run
        processor.process_directory(dry_run=False)
        
        # Check that files are modified
        for file_path in self.md_files:
            with open(file_path, "r") as f:
                content = f.read()
            self.assertIn("<!-- Processed by MockEditor -->", content)
    
    @mock.patch('editai.editors.folder_processor.logger')
    def test_error_handling(self, mock_logger):
        """Test that errors are handled gracefully."""
        # Create a problematic file
        error_file = self.test_dir / "error.md"
        with open(error_file, "w") as f:
            f.write("# Error file")
        
        # Create a mock editor that raises an exception
        class ErrorEditor(BaseEditor):
            def prerun_checks(self) -> bool:
                return True
            
            def collect_issues(self) -> None:
                pass
            
            def generate_v2(self) -> str:
                raise ValueError("Test error")
        
        processor = FolderProcessor(
            directory_path=self.test_dir,
            editor_class=ErrorEditor,
            include_pattern="error.md",
            recursive=False
        )
        
        # Process should not raise an exception
        results = processor.process_directory(dry_run=True)
        
        # Should be empty because the error was caught
        self.assertEqual(len(results), 0)
        
        # Logger should have been called with an error message
        mock_logger.error.assert_called_once()
        self.assertIn("Error processing file", mock_logger.error.call_args[0][0])
</file>

<file path=".python-version">
3.11
</file>

<file path="main.py">
def main():
    print("Hello from editor!")


if __name__ == "__main__":
    main()
</file>

<file path="test_sample.md">
# Test Document for Custom Rules

## Section 1: Passive Voice Examples

The data was processed by our system. The results are being generated as we speak. The analysis has been completed by the team.

Several issues were identified during the review. The bug has been fixed by the developers. The feature was implemented in the latest release.

## Section 2: Bullet Point Inconsistency

Benefits of our product:
* saves time
* Improving efficiency
* the cost is reduced.
* makes workflows smoother

Features to explore:
* Add new users
* editing documents
* share with team
* Export to PDF.
</file>

<file path="pyproject.toml">
[project]
name = "editai"
version = "0.1.0"
description = "A Python CLI tool for editing and improving Markdown documentation"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "diskcache>=5.6.3",
    "instructor>=1.7.9",
    "litellm>=1.67.2",
    "loguru>=0.7.3",
    "smolcrawl>=0.1.7",
    "spacy>=3.8.5",
    "typer>=0.15.2",
]

[project.optional-dependencies]
test = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
    "pytest-mock>=3.10.0",
    "pytest-asyncio>=0.21.0",
    "responses>=0.22.0",
]

[project.scripts]
editai = "editai.cli:app"

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = "test_*.py"
python_functions = "test_*"
</file>

<file path="README.md">
# EditAI

A Python tool for editing and improving Markdown documentation.

## Overview

EditAI provides various specialized editors for enhancing Markdown documentation:

- **Custom Rules Editor**: Apply user-defined editing rules from markdown files
- **Vale Editor**: Integrate with the Vale linting tool
- **AI Editor**: Use AI to identify and correct text issues
- **Internal Link Editor**: Add links between documents
- **Image Addition Editor**: Insert images into documents
- **Arbitrary Links Editor**: Interactive tool to add arbitrary links to a document

Each editor can process either single files or entire directories of markdown files.

## Installation

```bash
# Install from source
pip install -e .
```

## Usage

### Custom Rules Editor

Apply custom plaintext markdown rules to your document:

```bash
# Process a single file
python -m editai.cli custom-rules my-document.md ./rules/

# Process a directory of files
python -m editai.cli custom-rules ./docs/ ./rules/ --recursive
```

### Vale Editor

Apply Vale linting rules to your document:

```bash
# Process a single file
python -m editai.cli vale my-document.md --vale-config-path ./.vale.ini

# Process a directory of files
python -m editai.cli vale ./docs/ --vale-config-path ./.vale.ini --recursive
```

### AI Editor

Use AI to improve your document:

```bash
# Process a single file
python -m editai.cli ai my-document.md

# Process a directory of files
python -m editai.cli ai ./docs/ --recursive
```

### Internal Link Editor

Add internal links to your document:

```bash
# Process a single file
python -m editai.cli links my-document.md --local-index-names docs-index

# Process a directory of files
python -m editai.cli links ./docs/ --local-index-names docs-index --recursive
```

### Image Addition Editor

Add images to your document:

```bash
# Process a single file
python -m editai.cli add-images my-document.md ./images/ --image-url-prefix /images

# Process a directory of files
python -m editai.cli add-images ./docs/ ./images/ --image-url-prefix /images --recursive
```

### Arbitrary Links Editor

Interactive REPL to add arbitrary links to a document:

```bash
python -m editai.cli arbitrary-links my-document.md
```

Note: The arbitrary links editor does not support directory processing since it's interactive.

## Folder Processing

Process multiple files in a directory with a single command. Common options:

- `--recursive`: Process subdirectories recursively
- `--include-pattern`: Glob pattern for files to include (default: "*.md")
- `--exclude-patterns`: List of glob patterns for files to exclude
- `--dry-run`: Don't modify files, just show what would be changed

See the [folder processing documentation](docs/folder_processing.md) for more details.

## Custom Rules

Custom rules are plain markdown files containing editing instructions. Each rule file:

- Contains markdown instructions for a specific editing task
- Is processed by AI to interpret and apply changes
- Example rules: passive voice conversion, bullet point formatting

Managing rules:

```bash
# List all rules in a directory
python -m editai.cli list-rules ./rules/

# View a specific rule
python -m editai.cli view-rule ./rules/ passive_voice

# Create a new rule
python -m editai.cli create-rule ./rules/ my_new_rule
```

## Examples

Check the `examples/` directory for example files and usage scenarios.

## License

MIT
</file>

<file path=".gitignore">
# Python-generated files
__pycache__/
*.py[oc]
build/
dist/
wheels/
*.egg-info

# Virtual environments
.venv
.env
smolcrawl-data/
data/
storage/
**/.claude/settings.local.json
CLAUDE.md
plans/
</file>

</files>
